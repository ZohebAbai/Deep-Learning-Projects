{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders\n",
    "\n",
    "For feature detection, recommender systems, encoding.\n",
    "\n",
    "Hidden node should not more input nodes, that might overcomplete it. For that we use:\n",
    "* Sparse Autoencoders : Regularize by not using all hidden nodes.\n",
    "* Denoising Autoencoders : Random selection of input nodes\n",
    "* Contractive Autoencoders : adds penalty into the loss function backpropagated\n",
    "* Stacked : Adding more hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We start with an array where the lines correspond to the users and the columns correspond to the movies. Each cell contains ratings from 1 to 5 of movie i by user u.\n",
    "2. The first user goes into the network. The input vector x contains all its ratings for all the movies.\n",
    "3. The input vector x is encoded into a vector z of lower dimensions by mapping function f (e.g. sigmoid function, tanh) z- fW + b where w is weight vector of input weights and b the bias\n",
    "4. z is then decoded into output vector y of same dimension as x, aiming to replicate the input vector x.\n",
    "5. the reconstruction error is d(x,y) = ||x-y|| is computed. The goal is to minimize it.\n",
    "6. The error is back propagated. The weights are updated according to how much they are responsibe for the error. The learning rate decides by how much update the weights.\n",
    "7. The repeat 1 to 6. Reinforcement or Batch Learning.\n",
    "8. When whole dataset is passed through ANN the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                   1                             2\n",
       "0  1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1  2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2  3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3  4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4  5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1   2   3      4\n",
       "0  1  F   1  10  48067\n",
       "1  2  M  56  16  70072\n",
       "2  3  M  25  15  55117\n",
       "3  4  M  45   7  02460\n",
       "4  5  M  25  20  55455"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1  2          3\n",
       "0  1  1193  5  978300760\n",
       "1  1   661  3  978302109\n",
       "2  1   914  3  978301968\n",
       "3  1  3408  4  978300275\n",
       "4  1  2355  5  978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the training set and the test set\n",
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n",
    "training_set = np.array(training_set, dtype = 'int') #pytorch takes inputs as array\n",
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n",
    "test_set = np.array(test_set, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,         2,         3, 876893171],\n",
       "       [        1,         3,         4, 878542960],\n",
       "       [        1,         4,         3, 876893119],\n",
       "       ...,\n",
       "       [      943,      1188,         3, 888640250],\n",
       "       [      943,      1228,         3, 888640275],\n",
       "       [      943,      1330,         3, 888692465]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,        10,         3, 875693118],\n",
       "       [        1,        12,         5, 878542960],\n",
       "       [        1,        14,         5, 874965706],\n",
       "       ...,\n",
       "       [      459,       934,         3, 879563639],\n",
       "       [      460,        10,         3, 882912371],\n",
       "       [      462,       682,         5, 886365231]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the number of users and movies\n",
    "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of User 1: [Ratings of all the movies by User 1]\n",
    "\n",
    "List of User 2: [Ratings of all the movies by User 2]\n",
    "\n",
    "................................................................................\n",
    "\n",
    "List of User 943: [Ratings of all the movies by User 943]\n",
    "\n",
    "The new structure of data, having the shape of a 2d array where:\n",
    "\n",
    "the rows are the users,\n",
    "the columns are the movies,\n",
    "the cells are the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data into an array with users in lines and movies in columns\n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 3.0, 4.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data into Torch tensors\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 3., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 5., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the architecture of the Neural Network (Sparse Autoencoders)\n",
    "\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_movies, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        self.fc4 = nn.Linear(20, nb_movies)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 1.7719929318220722\n",
      "epoch: 2 loss: 1.096760158905915\n",
      "epoch: 3 loss: 1.0533094964245444\n",
      "epoch: 4 loss: 1.0383982444571715\n",
      "epoch: 5 loss: 1.0309382982452766\n",
      "epoch: 6 loss: 1.0265652068782372\n",
      "epoch: 7 loss: 1.0237284035617966\n",
      "epoch: 8 loss: 1.0219070052636214\n",
      "epoch: 9 loss: 1.0205892605646747\n",
      "epoch: 10 loss: 1.0197149291934113\n",
      "epoch: 11 loss: 1.0189747759361572\n",
      "epoch: 12 loss: 1.018246281084498\n",
      "epoch: 13 loss: 1.0178426867112027\n",
      "epoch: 14 loss: 1.017592415517041\n",
      "epoch: 15 loss: 1.0173394900170984\n",
      "epoch: 16 loss: 1.0168938809318402\n",
      "epoch: 17 loss: 1.0166501032386377\n",
      "epoch: 18 loss: 1.0166134474345925\n",
      "epoch: 19 loss: 1.0161801975558373\n",
      "epoch: 20 loss: 1.016196408324552\n",
      "epoch: 21 loss: 1.0159812203164016\n",
      "epoch: 22 loss: 1.0160233392152687\n",
      "epoch: 23 loss: 1.0158801475487444\n",
      "epoch: 24 loss: 1.0158160473735829\n",
      "epoch: 25 loss: 1.0158485653085103\n",
      "epoch: 26 loss: 1.015772427463776\n",
      "epoch: 27 loss: 1.0153465507614634\n",
      "epoch: 28 loss: 1.0149782115337054\n",
      "epoch: 29 loss: 1.0129961693909169\n",
      "epoch: 30 loss: 1.011251120490554\n",
      "epoch: 31 loss: 1.0101596093511298\n",
      "epoch: 32 loss: 1.0076405661268013\n",
      "epoch: 33 loss: 1.0079078058852817\n",
      "epoch: 34 loss: 1.004390861601477\n",
      "epoch: 35 loss: 1.0041932768930384\n",
      "epoch: 36 loss: 1.00050293205617\n",
      "epoch: 37 loss: 0.9972995078656034\n",
      "epoch: 38 loss: 0.9949197401644804\n",
      "epoch: 39 loss: 0.9958947655183975\n",
      "epoch: 40 loss: 0.9927845003939383\n",
      "epoch: 41 loss: 0.9931259527428764\n",
      "epoch: 42 loss: 0.9884447700426121\n",
      "epoch: 43 loss: 0.9892108617377965\n",
      "epoch: 44 loss: 0.9871002318443131\n",
      "epoch: 45 loss: 0.9853724135807992\n",
      "epoch: 46 loss: 0.983732637998511\n",
      "epoch: 47 loss: 0.9803979242122202\n",
      "epoch: 48 loss: 0.9767162324618007\n",
      "epoch: 49 loss: 0.9789065711590879\n",
      "epoch: 50 loss: 0.9734873696790538\n",
      "epoch: 51 loss: 0.9727185755560283\n",
      "epoch: 52 loss: 0.9686556530361932\n",
      "epoch: 53 loss: 0.9689065497709612\n",
      "epoch: 54 loss: 0.9668790544344728\n",
      "epoch: 55 loss: 0.9664470514271002\n",
      "epoch: 56 loss: 0.9649272834561786\n",
      "epoch: 57 loss: 0.9676819610608757\n",
      "epoch: 58 loss: 0.9707296243706727\n",
      "epoch: 59 loss: 0.9681572745563456\n",
      "epoch: 60 loss: 0.9671580070517495\n",
      "epoch: 61 loss: 0.964185534113354\n",
      "epoch: 62 loss: 0.9614478410932613\n",
      "epoch: 63 loss: 0.9624935010077603\n",
      "epoch: 64 loss: 0.9586709396183852\n",
      "epoch: 65 loss: 0.9588329672113052\n",
      "epoch: 66 loss: 0.9563036930329529\n",
      "epoch: 67 loss: 0.9566756553693885\n",
      "epoch: 68 loss: 0.9529659562814514\n",
      "epoch: 69 loss: 0.9549048650813069\n",
      "epoch: 70 loss: 0.9528430589172732\n",
      "epoch: 71 loss: 0.9561555988934779\n",
      "epoch: 72 loss: 0.9500657352578942\n",
      "epoch: 73 loss: 0.9503990764279395\n",
      "epoch: 74 loss: 0.9478309416392803\n",
      "epoch: 75 loss: 0.9479197673325025\n",
      "epoch: 76 loss: 0.9454158277922271\n",
      "epoch: 77 loss: 0.9456203362208302\n",
      "epoch: 78 loss: 0.9440905275505482\n",
      "epoch: 79 loss: 0.9436622684234496\n",
      "epoch: 80 loss: 0.9417204738049765\n",
      "epoch: 81 loss: 0.9426378729318254\n",
      "epoch: 82 loss: 0.940809298600773\n",
      "epoch: 83 loss: 0.9411620713790803\n",
      "epoch: 84 loss: 0.9396562556158122\n",
      "epoch: 85 loss: 0.9406311816064254\n",
      "epoch: 86 loss: 0.93769005965885\n",
      "epoch: 87 loss: 0.9382056214288083\n",
      "epoch: 88 loss: 0.9362600173919359\n",
      "epoch: 89 loss: 0.938065414189752\n",
      "epoch: 90 loss: 0.9357834530913771\n",
      "epoch: 91 loss: 0.9376034422976696\n",
      "epoch: 92 loss: 0.9355764981159657\n",
      "epoch: 93 loss: 0.936891847514907\n",
      "epoch: 94 loss: 0.9347224137818808\n",
      "epoch: 95 loss: 0.9351593112041434\n",
      "epoch: 96 loss: 0.9339094276280139\n",
      "epoch: 97 loss: 0.9344613198960682\n",
      "epoch: 98 loss: 0.9327193726826367\n",
      "epoch: 99 loss: 0.9337417691668427\n",
      "epoch: 100 loss: 0.9325107930050749\n"
     ]
    }
   ],
   "source": [
    "# Training the SAE\n",
    "# With unsqueeze you parse a dimension into your tensor, and therefore you need to set the shape of your indexed tensor at \n",
    "# index 0 for both target and input equal, to run tensors with each other.\n",
    "nb_epoch = 100\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(nb_users):\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.item()*mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.9604290318022629\n"
     ]
    }
   ],
   "source": [
    "# Testing the SAE\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        target.require_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.item()*mean_corrector)\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
