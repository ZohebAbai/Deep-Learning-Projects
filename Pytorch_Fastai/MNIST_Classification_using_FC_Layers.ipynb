{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Classification using FC Layers.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZohebAbai/DeepLearning-Projects/blob/master/MNIST_Classification_using_FC_Layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9HyHwl99IuVC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exploring the data"
      ]
    },
    {
      "metadata": {
        "id": "SaJMcXI_IzsW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`torchvision` contains some utilities for working with image data. It also contains helper classes to automatically download and import popular datasets like MNIST."
      ]
    },
    {
      "metadata": {
        "id": "cTNyo6J4_gsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HOco6_KqJUbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "c9c0517f-50cb-4866-850e-0170991e0bba"
      },
      "cell_type": "code",
      "source": [
        "dataset = MNIST(root='data/', download=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:02, 4550951.76it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 67503.97it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:01, 1128388.18it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 25641.25it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wXbpteGQJdIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7746f23-8a2f-4eda-a47a-dd05ba2212b9"
      },
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "f2SVmO2oJucB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The dataset has 60,000 images which can be used to train the model. There is also an additional test set of 10,000 images which can be created by passing train=False to the MNIST class."
      ]
    },
    {
      "metadata": {
        "id": "0zPSdqBGJtZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aaca9915-ba05-49a4-e89f-724a3dfb3a64"
      },
      "cell_type": "code",
      "source": [
        "test_dataset = MNIST(root='data/', train=False)\n",
        "len(test_dataset)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "1_yRuJZlJtH4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "55033e0a-37de-4fa9-81d2-25f6e23e125e"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "image, label = dataset[0]\n",
        "plt.imshow(image, cmap='gray')\n",
        "print('Label:', label)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "N2zVZYcSNfRh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ScqmTXuPLa3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`torchvision.transforms` contains many such predefined functions, and we'll use the ToTensor transform to convert images into PyTorch tensors."
      ]
    },
    {
      "metadata": {
        "id": "CZKLV-rFPLGO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = MNIST(root='data/', train=True, \n",
        "                transform=transforms.ToTensor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HMS1V9cVP41q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eaa18b52-49f9-493b-9057-644189760459"
      },
      "cell_type": "code",
      "source": [
        "img_tensor, label = dataset[0]\n",
        "print(img_tensor.shape, label)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28]) 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xwz64eNyQFTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d0b7702-40b6-4465-e3ef-8fe79ce6b6a0"
      },
      "cell_type": "code",
      "source": [
        "print(torch.max(img_tensor), torch.min(img_tensor))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.) tensor(0.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yb078nc7QdBZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The values range from 0 to 1, with 0 representing black, 1 white and the values in between different shades of grey. "
      ]
    },
    {
      "metadata": {
        "id": "L6eD7nujQ08H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Splitting the datasets"
      ]
    },
    {
      "metadata": {
        "id": "j9eBKL8qRC2r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "While building real world machine learning models, it is quite common to split the dataset into 3 parts:\n",
        "\n",
        "* Training set — used to train the model i.e. compute the loss and adjust the weights of the model using gradient descent.\n",
        "* Validation set — used to evaluate the model while training, adjust hyperparameters (learning rate etc.) and pick the best version of the model.\n",
        "* Test set — used to compare different models, or different types of modeling approaches, and report the final accuracy of the model.\n",
        "\n",
        "In the MNIST dataset, there are 60,000 training images, and 10,000 test images. The test set is standardized so that different researchers can report the results of their models against the same set of images. Since there’s no predefined validation set, we must manually split the 60,000 images into training and validation datasets."
      ]
    },
    {
      "metadata": {
        "id": "jrSHB14LQY-n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def split_indices(n, val_pct):\n",
        "  \n",
        "  #determine the size of validation set\n",
        "  n_val = int(val_pct*n)\n",
        "  \n",
        "  #create random permutation of 0 to n-1\n",
        "  idxs = np.random.permutation(n)\n",
        "  \n",
        "  #pick first n_val indices for validation set\n",
        "  return idxs[n_val:], idxs[:n_val]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9FZspUYVuF6z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`split_indices` randomly shuffles the array indices 0,1,..n-1, and separates out a desired portion from it for the validation set. It's important to shuffle the indices before creating a validation set, because the training images are often ordered by the target labels i.e. images of 0s, followed by images of 1s, followed by images of 2s and so on. If we were to pick a 20% validation set simply by selecting the last 20% of the images, the validation set would only consist of images of 8s and 9s, whereas the training set would contain no images of 8s and 9s. This would make it impossible to train a good model using the training set, which also performs well on the validation set (and on real world data)."
      ]
    },
    {
      "metadata": {
        "id": "0depVOEYuE3g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bc744bc-6788-43cd-8ed4-25a34ad84153"
      },
      "cell_type": "code",
      "source": [
        "train_indices, val_indices = split_indices(len(dataset), val_pct=0.20)\n",
        "print(len(train_indices), len(val_indices))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48000 12000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0yqybv15vjxX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can now create PyTorch data loaders for each of these using a `SubsetRandomSampler`, which samples elements randomly from a given list of indices, while creating batches of data."
      ]
    },
    {
      "metadata": {
        "id": "YubDrDv0vV6u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_finCm9Rv3h1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size=64\n",
        "\n",
        "#Training sampler and dataloader\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "train_loader = DataLoader(dataset, batch_size,sampler= train_sampler)\n",
        "\n",
        "#Validation sampler and data loader\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "val_loader = DataLoader(dataset, batch_size, sampler= val_sampler)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mCLwpm85xUud",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build the model"
      ]
    },
    {
      "metadata": {
        "id": "z6Wita6axmpw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For a **logistic regression** model, nn.Linear expects the each training example to be a vector, each 1x28x28 image tensor needs to be flattened out into a vector of size 784 (28*28), before being passed into the model."
      ]
    },
    {
      "metadata": {
        "id": "6cmKUCE8wu8P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "input_size= 28*28\n",
        "num_classes = 10\n",
        "\n",
        "class MnistModel(nn.Module):\n",
        "  \"\"\"Feedforward NN with 1 hidden layer\"\"\"\n",
        "  def __init__(self, in_size, hidden_size, out_size):\n",
        "    super().__init__()\n",
        "    \n",
        "    #Hidden Layer\n",
        "    self.linear1 = nn.Linear(in_size, hidden_size)\n",
        "    \n",
        "    #Output Layer\n",
        "    self.linear2 = nn.Linear(hidden_size, out_size)\n",
        "    \n",
        "  def forward(self, xb):\n",
        "    #Flatten the image tensors\n",
        "    xb = xb.view(xb.size(0), -1)\n",
        "    \n",
        "    #Get intermediate outputs using hidden layers \n",
        "    out = self.linear1(xb)\n",
        "    \n",
        "    #Apply activation function\n",
        "    out = F.relu(out)\n",
        "    \n",
        "    #Get predictions using output layer\n",
        "    out = self.linear2(out)\n",
        "    \n",
        "    return out\n",
        "\n",
        "#model = MnistModel()\n",
        "#print(model.linear.weight.shape, model.linear.bias.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yv9MdAqwGXZs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using GPU"
      ]
    },
    {
      "metadata": {
        "id": "MBZhXjpSGZ56",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "  \"\"\"Pick GPUif available, else CPU\"\"\"\n",
        "  if torch.cuda.is_available():\n",
        "    return torch.device('cuda')\n",
        "  else:\n",
        "    return torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8vIGNlfIbogP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = get_default_device()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KHcKvYd3IDaT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_device(data, device):\n",
        "  \"\"\"Move tensors to chosen device\"\"\"\n",
        "  if isinstance(data, (list, tuple)):\n",
        "    return [to_device(x, device) for x in data]\n",
        "  return data.to(device, non_blocking=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "klyGZIF8JGQa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DeviceDataLoader():\n",
        "  \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "  def __init__(self, dl, device):\n",
        "    self.dl = dl\n",
        "    self.device = device\n",
        "    \n",
        "  def __iter__(self):\n",
        "    \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "    for b in self.dl:\n",
        "      yield to_device(b, self.device)\n",
        "      \n",
        "  def __len__(self):\n",
        "    \"\"\"Number of batches\"\"\"\n",
        "    return len(self.dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m0fzo3aOJGpg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Wrap the data loader using DeviceDataLoader\n",
        "train_dl = DeviceDataLoader(train_loader, device)\n",
        "valid_dl = DeviceDataLoader(val_loader, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bP4aaPmpJN7E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ]
    },
    {
      "metadata": {
        "id": "45k7DcfTQ1vu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need to define the accuracy to operate on an entire batch of outputs directly, so that we can use it as a metric in `fit`."
      ]
    },
    {
      "metadata": {
        "id": "pp_dKJygQ58t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "  #determine the predicted label for each image by simply choosing \n",
        "  #the index of the element with the highest probability in each output row.\n",
        "  _,preds = torch.max(outputs, dim=1)\n",
        "  return torch.sum(preds == labels).item() / len(preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mAhE9LDTKQwC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "While the `accuracy` is a great way for us (humans) to evaluate the model, it can’t be used as a loss function for optimizing our model using gradient descent, for the following reasons:\n",
        "\n",
        "* It’s not a differentiable function. `torch.max` and `==` are both non-continuous and non-differentiable operations, so we can't use the accuracy for computing gradients w.r.t the weights and biases.\n",
        "* It doesn’t take into account the actual probabilities predicted by the model, so it can’t provide sufficient feedback for incremental improvements.\n",
        "\n",
        "Unlike `accuracy`, `cross-entropy` is a continuous and differentiable function that also provides good feedback for incremental improvements in the model (a slightly higher probability for the correct label leads to a lower loss). This makes it a good choice for the loss function. It also performs softmax internally, so we can directly pass in the outputs of the model without converting them into probabilities.\n",
        "\n",
        "Cross entropy is the negative logarithm of the predicted probability of the correct label averaged over all training samples."
      ]
    },
    {
      "metadata": {
        "id": "T8QStOYeIu3w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "loss_fn = F.cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "in-S8a0aN1lz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We define a function loss_batch which:\n",
        "\n",
        "* calculates the loss for a batch of data\n",
        "* optionally perform the gradient descent update step if an optimizer is provided\n",
        "* optionally computes a metric (e.g. accuracy) using the predictions and actual targets\n"
      ]
    },
    {
      "metadata": {
        "id": "kAFWJBO2MdqV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss_batch(model, loss_func, xb, yb, opt=None, metric=None):\n",
        "  \n",
        "  #Calculate loss\n",
        "  preds = model(xb)\n",
        "  loss = loss_func(preds, yb)\n",
        "  \n",
        "  if opt is not None:\n",
        "    #Compute gradients\n",
        "    loss.backward()\n",
        "    #Update parameters\n",
        "    opt.step()\n",
        "    #Reset gradients\n",
        "    opt.zero_grad()\n",
        "    \n",
        "  metric_result = None\n",
        "  if metric is not None:\n",
        "    #compute metric\n",
        "    metric_result = metric(preds, yb)\n",
        "      \n",
        "  return loss.item(), len(xb), metric_result "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HP7u1MI5O8SY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The optimizer is an optional argument, to ensure that we can reuse `loss_batch` for computing the loss on the validation set. We also return the length of the batch as part of the result, as it'll be useful while combining the losses/metrics for the entire dataset.\n",
        "\n",
        "Next we define a function evaluate, which calculates the overall loss (and a metric, if provided) for the validation set."
      ]
    },
    {
      "metadata": {
        "id": "csSRnBNHPANa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(model, loss_fn, valid_dl, metric=None):\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    #Pass each batch through the model\n",
        "    results = [loss_batch(model, loss_fn, xb, yb, metric=metric) for xb, yb in valid_dl]\n",
        "    \n",
        "    #Separate losses, counts and metrics\n",
        "    losses, nums, metrics = zip(*results)\n",
        "    \n",
        "    #Total size of dataset\n",
        "    total = np.sum(nums)\n",
        "    \n",
        "    #Avg. loss across batches\n",
        "    avg_loss = np.sum(np.multiply(losses, nums)) / total\n",
        "    avg_metric = None\n",
        "    if metric is not None:\n",
        "      #avg of metric across batches\n",
        "      avg_metric = np.sum(np.multiply(metrics, nums)) / total\n",
        "  \n",
        "  return avg_loss, total, avg_metric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vso-DV3sSIM6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's define the `fit` function using loss_batch and evaluate."
      ]
    },
    {
      "metadata": {
        "id": "v972OCRMSM3v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fit(epochs, lr, model, loss_fn, train_dl, \n",
        "        valid_dl, metric=None, opt_fn=None):\n",
        "  \n",
        "  losses, metrics = [],[]\n",
        "  \n",
        "  #Instantiate the optimizer\n",
        "  if opt_fn is None: opt_fn = torch.optim.Adam\n",
        "  opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    #Training\n",
        "    for xb, yb in train_dl:\n",
        "      loss,_,_ = loss_batch(model, loss_fn, xb, yb, opt)\n",
        "      \n",
        "    #Evaluation\n",
        "    result = evaluate(model, loss_fn, valid_dl, metric)\n",
        "    val_loss, total, val_metric = result\n",
        "    \n",
        "    #Record the loss and metric\n",
        "    losses.append(val_loss)\n",
        "    metrics.append(val_metric)\n",
        "    \n",
        "    #Print progress\n",
        "    if metric is None:\n",
        "      print('Epoch [{}/{}], Loss: {:.4f}'.format\n",
        "           (epoch+1, epochs, val_loss))\n",
        "    else:\n",
        "      print('Epoch [{}/{}], Loss: {:.4f}, {}: {:.4f}'.format\n",
        "           (epoch+1, epochs, val_loss, metric.__name__, val_metric))\n",
        "      \n",
        "  return losses, metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9U36DYclLFCw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "f26aec68-2ae9-4aa4-c7da-857d0eee6376"
      },
      "cell_type": "code",
      "source": [
        "#Lets train the model\n",
        "model = MnistModel(input_size, hidden_size=128, out_size=num_classes)\n",
        "to_device(model, device)\n",
        "\n",
        "#Fit\n",
        "losses, metrics = fit(20, 0.001, model, loss_fn, train_dl, valid_dl, metric=accuracy)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Loss: 0.2103, accuracy: 0.9388\n",
            "Epoch [2/20], Loss: 0.1512, accuracy: 0.9564\n",
            "Epoch [3/20], Loss: 0.1168, accuracy: 0.9654\n",
            "Epoch [4/20], Loss: 0.0986, accuracy: 0.9708\n",
            "Epoch [5/20], Loss: 0.0919, accuracy: 0.9727\n",
            "Epoch [6/20], Loss: 0.0817, accuracy: 0.9758\n",
            "Epoch [7/20], Loss: 0.0738, accuracy: 0.9773\n",
            "Epoch [8/20], Loss: 0.0761, accuracy: 0.9767\n",
            "Epoch [9/20], Loss: 0.0720, accuracy: 0.9771\n",
            "Epoch [10/20], Loss: 0.0740, accuracy: 0.9786\n",
            "Epoch [11/20], Loss: 0.0735, accuracy: 0.9781\n",
            "Epoch [12/20], Loss: 0.0748, accuracy: 0.9782\n",
            "Epoch [13/20], Loss: 0.0781, accuracy: 0.9772\n",
            "Epoch [14/20], Loss: 0.0799, accuracy: 0.9774\n",
            "Epoch [15/20], Loss: 0.0808, accuracy: 0.9782\n",
            "Epoch [16/20], Loss: 0.0800, accuracy: 0.9788\n",
            "Epoch [17/20], Loss: 0.0806, accuracy: 0.9780\n",
            "Epoch [18/20], Loss: 0.0825, accuracy: 0.9793\n",
            "Epoch [19/20], Loss: 0.0833, accuracy: 0.9773\n",
            "Epoch [20/20], Loss: 0.0826, accuracy: 0.9797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fnCrwEpOMeXO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Parameters like batch size, learning rate etc. need to picked in advance while training machine learning models, and are called hyperparameters. Picking the right hyperparameters is critical for training an accurate model within a reasonable amount of time, and is an active area of research and experimentation."
      ]
    },
    {
      "metadata": {
        "id": "_4zjHyNrSese",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualization"
      ]
    },
    {
      "metadata": {
        "id": "y2r5x3UQSeWx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "bb1e9659-1f24-488b-c21e-fb50a6d1c0a3"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(metrics, '-x')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Accuracy vs No. of epochs')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Accuracy vs No. of epochs')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+1WgyuawtwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4w4qk2Uuko1w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test the model"
      ]
    },
    {
      "metadata": {
        "id": "BgceEx50pHN-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#convert test image dataset to pytorch tensors\n",
        "test_dataset = MNIST(root='data/', train=False, \n",
        "                     transform=transforms.ToTensor())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UcsCWAtZlW2j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let’s also look at the overall loss and accuracy of the model on the test set.\n"
      ]
    },
    {
      "metadata": {
        "id": "N8-cDmeRlXzc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ae48af7-11c5-4434-d2ff-cf68a667b00c"
      },
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "test_dl = DeviceDataLoader(test_loader, device)\n",
        "\n",
        "test_loss, total, test_acc = evaluate(model, loss_fn, test_dl,\n",
        "                                     metric=accuracy)\n",
        "print('Loss: {:.4f}, Accuracy: {:.4f}'.format\n",
        "     (test_loss, test_acc))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.0913, Accuracy: 0.9772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bXaS5_2olyoR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Save the Model"
      ]
    },
    {
      "metadata": {
        "id": "K14vx8cLl0qW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'mnist-logistic.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0aCbBM40mPbI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the Model"
      ]
    },
    {
      "metadata": {
        "id": "qjg4U7WQl9lX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2 = MnistModel(input_size, hidden_size=128, out_size=num_classes)\n",
        "model2.load_state_dict(torch.load('mnist-logistic.pth'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WtsSdseQplOw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}