{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inria_Preprocessing_SlidingWindowPatches_250.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oKeh2HQXcPY",
        "colab_type": "text"
      },
      "source": [
        "## **Inria Aerial Satellite Image Labelling**\n",
        "The main aim of this challenge is to be able to classify pixels as 'building' or 'not building'. This is a clear case of semantic segmentation. We have180 aerial images from various cities with a resolution of 5000 X 5000, along with the segmented masks of 5000 X 5000. Our goal is to classify each of the pixels in the test image and generate a masks for the test images too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqCQtcktF0kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash\n",
        "!pip install PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x10JWzM1BGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4weziruaEBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile,re,os,pathlib,shutil\n",
        "\n",
        "import fastai\n",
        "from fastai.vision import *\n",
        "import torch\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMqPP8KxX_Zc",
        "colab_type": "text"
      },
      "source": [
        "## Download Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAhBTN6qyBBo",
        "colab_type": "text"
      },
      "source": [
        "Downloading the dataset images from the URL mentioned in the inria site using curl cmd. This command downloads the dataset as 7z parts and then unzips it under the folder AerialImageDataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3GI6p0MXqV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do not execute !! Already downloaded datasets !\n",
        "!curl -k https://files.inria.fr/aerialimagelabeling/getAerial.sh | bash"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dv7ayja6qjX",
        "colab_type": "text"
      },
      "source": [
        "Remove dependent 7z parts and zip file once unzipping is completed to clear some storage space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXG_e3ugsZAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/aerialimagelabeling*\n",
        "!rm -rf /content/NEW2-AerialImageDataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r802b5aZCIV2",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess the data \n",
        "Since each image is of a high dimension and we only have 180 training images, we can take 2 approaches - \n",
        "1) Resize the image to lower dimensions like 250 X 250 and then train the network on the resized images. We can resize the images while creating the data bunch.\n",
        "2) Slice each image of 5k X 5k over a sliding window of 250 to generate an image of size 250 X 250 and train the network on the patches. This approach generates ~400 image patches for each 5k X 5k image. This is a preprocessing step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMIRg8NTCG1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = Path('/content/AerialImageDataset/train/images')\n",
        "mask_path = Path('/content/AerialImageDataset/train/gt')\n",
        "test_path = Path('/content/AerialImageDataset/test/images')\n",
        "valid_path = Path('/content/AerialImageDataset/valid')\n",
        "\n",
        "images_patch_path = Path('/content/AerialImagePatches/train')\n",
        "masks_patch_path = Path('/content/AerialImagePatches/masks')\n",
        "tests_patch_path = Path('/content/AerialImagePatches/test')\n",
        "valids_patch_path = Path('/content/AerialImagePatches/valid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUe_KfYrfr2O",
        "colab_type": "text"
      },
      "source": [
        "Split train to valid by moving the first 5 images from each city to valid folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SRR9XrzfqM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#move first five images from each city for valid hold outs\n",
        "\n",
        "def train_valid_split(src: str, dst: str):\n",
        "  if not os.path.isdir(dst):\n",
        "    dst.mkdir(parents=True, exist_ok=True)\n",
        "  for file in os.listdir(src):\n",
        "    if re.match(\"[a-zA-Z]*[1-5]{1}\\.tif\", file) or re.match(\"[a-zA-Z]*-\\w[1-5]{1}\\.tif\", file):\n",
        "      shutil.move(src/file, dst/file)\n",
        "        \n",
        "train_valid_split(img_path,valid_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBCUlr0uQ0_H",
        "colab_type": "text"
      },
      "source": [
        "Clean up any previously created folder for AerialImagePatches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiYVAHaMQ94Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/AerialImagePatches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8HzXjLFDkvG",
        "colab_type": "text"
      },
      "source": [
        "Functions to generate patches of 250 X 250 from 5k X 5k images and save it for training model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Svtt1GHNiEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "orig_images = ImageList.from_folder(img_path)\n",
        "orig_valids = ImageList.from_folder(valid_path)\n",
        "orig_masks = ImageList.from_folder(mask_path)\n",
        "orig_tests = ImageList.from_folder(test_path)\n",
        "\n",
        "get_patch_file_name = lambda pth,x,y: pth/f'{x.stem.split(\"/\")[-1]}_{y}.tif'\n",
        "\n",
        "size = 250\n",
        "step = 250\n",
        "\n",
        "\n",
        "def generate_patches(image, i, dest_img_path, channels:int, size:int, step:int):\n",
        "  img = open_image(image)\n",
        "  \n",
        "  patches = img.data.unfold(0, channels, channels).unfold(1, size, step).unfold(2, size, step)\n",
        "  cnt=1\n",
        "  for i in range(patches.shape[0]):\n",
        "    for j in range(patches.shape[1]):\n",
        "      for k in range(patches.shape[2]):\n",
        "        patch = patches[i][j][k]\n",
        "        imgpil = F.to_pil_image(patch)\n",
        "        filname = get_patch_file_name(dest_img_path, image, cnt)\n",
        "        cnt=cnt+1\n",
        "        imgpil.save(filname)\n",
        "\n",
        "# create smaller patch sets \n",
        "sets = [(orig_images,images_patch_path,3,size,step),(orig_valids,valids_patch_path,3,size,step),(orig_masks, masks_patch_path,3,size,step),(orig_tests,tests_patch_path,3,size,step)]\n",
        "for img_lst,dst_path,channels,size,step in sets:\n",
        "  if not dst_path.exists():\n",
        "    dst_path.mkdir(parents=True, exist_ok=True)\n",
        "  parallel(partial(generate_patches, dest_img_path=dst_path, channels=channels, size=size, step=step), img_lst.items)\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4vtpgi3EIsu",
        "colab_type": "text"
      },
      "source": [
        "Now, the training set of 180 images of 5k x 5k is converted into a training set of 60450 patches of 250 x 250 each, along with corresponding 60450 patches for the masks as well. Valid set contains 9750 patches of 250 x 250."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqJXDynVb3om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(get_image_files(img_path)),len(get_image_files(mask_path)),len(get_image_files(valid_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxuBnW9AbDgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(get_image_files(images_patch_path)),len(get_image_files(masks_patch_path)), len(get_image_files(valids_patch_path)), len(get_image_files(tests_patch_path))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJfXmmLijpq0",
        "colab_type": "text"
      },
      "source": [
        "Function to create tar file for moving to Drive for future use. This helps in avoiding redundant preprocessing each time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQA2w_khnWiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_source_dir = '/content/AerialImagePatches/train'\n",
        "valid_source_dir = '/content/AerialImagePatches/valid'\n",
        "mask_source_dir = '/content/AerialImagePatches/masks'\n",
        "test_source_dir = '/content/AerialImagePatches/test'\n",
        "\n",
        "def make_tarfile(output_filename, source_dir):\n",
        "  with tarfile.open(output_filename, \"w:gz\") as tar:\n",
        "    tar.add(source_dir, arcname=os.path.basename(source_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0j8JTMfG3sL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_tarfile('train.tar', train_source_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io1NoYQ7xHNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_tarfile('masks.tar', mask_source_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6ej7bU8ntH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_tarfile('valid.tar', valid_source_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c78IQr-knMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tar test folder only when needed as Drive only has 15GB by default\n",
        "make_tarfile('test.tar', test_source_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B82GCKalFho",
        "colab_type": "text"
      },
      "source": [
        "Function to upload to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2PEoLX6bDIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create GoogleDrive instance with authenticated GoogleAuth instance.\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "def upload_to_drive(file, title):\n",
        "  uploaded = drive.CreateFile({'title': title})\n",
        "  uploaded.SetContentFile(file)\n",
        "  uploaded.Upload()\n",
        "  print('Uploaded file %s with ID %s'%(file, uploaded.get('id')))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld8Wr3o3llFk",
        "colab_type": "code",
        "outputId": "c9f0e304-6fef-40bd-f182-3fb07ef99b54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "upload_to_drive(\"train.tar\",\"train.tar\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file train.tar with ID 1R9iYFeRbzqnXCu86SFGRnitXSZqP9a8Q\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i85HBtFDlzay",
        "colab_type": "code",
        "outputId": "c21ba774-6379-4459-9b68-b30e7ca098ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "upload_to_drive(\"masks.tar\",\"masks.tar\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file masks.tar with ID 1M2CrjMnrBTZHjFf_xiZAkBdrIkecDSKb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbkeYl04efPO",
        "colab_type": "code",
        "outputId": "c899924b-5390-472d-ed14-68812c83048b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "upload_to_drive(\"valid.tar\",\"valid.tar\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file valid.tar with ID 1xNaoByxiuao1ViYyjnqT2aNSE-jSbNoy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tECv-wTJml8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upload_to_drive(\"test.tar\",\"test.tar\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GFNkc41lvgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}