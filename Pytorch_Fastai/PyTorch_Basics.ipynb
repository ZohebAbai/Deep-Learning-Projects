{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Basics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZohebAbai/DeepLearning-Projects/blob/master/PyTorch_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "j3I6dTMOcUJl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tensors and Gradients"
      ]
    },
    {
      "metadata": {
        "id": "Wx7SDmKkL3nf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8NEjrxNLMiKm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A tensor is a number, vector, matrix or any n-dimensional array."
      ]
    },
    {
      "metadata": {
        "id": "EctWxZQTMFKK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30e24cc8-8712-4c1f-ac14-e6d290acce9c"
      },
      "cell_type": "code",
      "source": [
        "# Number\n",
        "t1 = torch.tensor(4.)\n",
        "t1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "wbjxGCz8Mtl8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "857ee5b5-d8e0-41e1-f5c9-c1b0c1cceb2a"
      },
      "cell_type": "code",
      "source": [
        "t1.dtype"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "xzG4Lo7mM5nI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c2254e2-90f7-4d85-e9fe-f4088d9a8dd7"
      },
      "cell_type": "code",
      "source": [
        "# Vector\n",
        "t2 = torch.tensor([1., 2, 3, 4])\n",
        "t2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "RQ2l-ShgVNPn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "005a83a6-08ee-4b21-ee83-3704da889f7c"
      },
      "cell_type": "code",
      "source": [
        "# Matrix\n",
        "t3 = torch.tensor([[5.,6], [7,8], [9,10]])\n",
        "t3"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "7krR6-NmVi2X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6623ff77-8647-4e5c-b401-d5116e91a575"
      },
      "cell_type": "code",
      "source": [
        "# 3D array\n",
        "t4 = torch.tensor([\n",
        "    [[11, 12, 13],\n",
        "    [13, 14, 15]],\n",
        "    [[15, 16, 17],\n",
        "    [17,18,19]]\n",
        "])\n",
        "t4"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[11, 12, 13],\n",
              "         [13, 14, 15]],\n",
              "\n",
              "        [[15, 16, 17],\n",
              "         [17, 18, 19]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "OqGr4XciWF-t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tensors can have any number of dimensions, and different lengths along each dimension. "
      ]
    },
    {
      "metadata": {
        "id": "O8ykJrqjV8oC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3ee1112d-1058-4fba-f4b2-485e8e155478"
      },
      "cell_type": "code",
      "source": [
        "print(t1.shape)\n",
        "print(t2.shape)\n",
        "print(t3.shape)\n",
        "print(t4.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([])\n",
            "torch.Size([4])\n",
            "torch.Size([3, 2])\n",
            "torch.Size([2, 2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B_5-ioMcXFIN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tensors operations and gradients"
      ]
    },
    {
      "metadata": {
        "id": "9gbM_kmAWPex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b87ee14-0d72-4721-90ac-706ee5ead24d"
      },
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True)\n",
        "b = torch.tensor(5., requires_grad=True)\n",
        "y = w*x + b\n",
        "y"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "JtdGZekdX0dA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As expected, y is a tensor with the value 3 * 4 + 5 = 17. What makes PyTorch special is that we can automatically compute the derivative of y w.r.t. the tensors that have requires_grad set to True i.e. w and b. To compute the derivatives, we can call the .backward method on our result y."
      ]
    },
    {
      "metadata": {
        "id": "SCxwaGySX2SE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "19a292cd-196f-436a-e8ea-92fa21ac3033"
      },
      "cell_type": "code",
      "source": [
        "# Compute derivatives\n",
        "y.backward()\n",
        "\n",
        "#Display the gradients\n",
        "print('dy/dx:', x.grad)\n",
        "print('dy/dw:', w.grad)\n",
        "print('dy/db:', b.grad)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dy/dx: None\n",
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D4gkpGgJZlT0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Interoperability with Numpy"
      ]
    },
    {
      "metadata": {
        "id": "NcTxGWbCY5r9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4412f622-5f0e-4dce-f871-e510b775641b"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.array([[1,2], [3,4]])\n",
        "print(x)\n",
        "y = torch.from_numpy(x)\n",
        "print(y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7bNe9cdSZ9aI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2798cb04-79fe-497c-e70a-270a4fc13b21"
      },
      "cell_type": "code",
      "source": [
        "print(x.dtype)\n",
        "print(y.dtype)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "int64\n",
            "torch.int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iap0ZTEnaGuo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7a40db92-098c-4200-e629-5b09ae88b4aa"
      },
      "cell_type": "code",
      "source": [
        "z= y.numpy()\n",
        "print(z)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pie6ODoVccDs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Linear Regression and Gradient Descent"
      ]
    },
    {
      "metadata": {
        "id": "WmId_4w4as0-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Input (temp, rqinfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                  [91, 88, 64],\n",
        "                  [87, 134, 58],\n",
        "                  [102, 43, 37],\n",
        "                  [69, 96, 70]], dtype= 'float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ntwN3NYhf9Xe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70],\n",
        "                   [81, 101],\n",
        "                   [119, 133],\n",
        "                   [22, 37],\n",
        "                   [103, 119]], dtype= 'float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f_rfxqM7gL6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "595daf0b-0e64-47b3-aade-3f253479b319"
      },
      "cell_type": "code",
      "source": [
        "#Convert inputa and targets to tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KVn58csMgqXP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bdba96c7-7eae-4c15-c968-77e73d24c239"
      },
      "cell_type": "code",
      "source": [
        "#Weights and biases\n",
        "w = torch.randn(2,3, requires_grad= True)\n",
        "b = torch.randn(2, requires_grad= True)\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.9525,  0.3977,  0.3852],\n",
            "        [ 0.6867, -1.0630, -0.1848]], requires_grad=True)\n",
            "tensor([-0.0781,  0.1031], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ov4m2eeVhSrL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`torch.randn` creates a tensor with the given shape, with elements picked randomly from a normal distribution with mean 0 and standard deviation 1."
      ]
    },
    {
      "metadata": {
        "id": "B97OVa1ohKZL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(x):\n",
        "  return x @ w.t() + b "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F8Mubcuih6hB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "@ represents matrix multiplication in PyTorch, and the .t method returns the transpose of a tensor."
      ]
    },
    {
      "metadata": {
        "id": "clnenmnphyij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9ba60adc-dbd5-467a-8332-0cd556b16d9c"
      },
      "cell_type": "code",
      "source": [
        "#Predictions\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[112.6665, -28.9285],\n",
            "        [146.2532, -42.7698],\n",
            "        [158.4252, -93.3038],\n",
            "        [128.4344,  17.6067],\n",
            "        [130.7902, -67.4906]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EAkZh5qeiQ_S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There’s a huge difference between the predictions of our model, and the actual values of the target variables."
      ]
    },
    {
      "metadata": {
        "id": "w9lm8hzYihnw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loss Function"
      ]
    },
    {
      "metadata": {
        "id": "jSnf2UbCiGOs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#MSE loss\n",
        "def mse(t1, t2):\n",
        "  diff = t1-t2\n",
        "  return torch.sum(diff*diff) / diff.numel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3hUQTADjiyI4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ".numel method returns the number of elements in a tensor."
      ]
    },
    {
      "metadata": {
        "id": "EMnSXP4_ivJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fdf9d83-ce48-4c5b-ed0a-71c46fc9240c"
      },
      "cell_type": "code",
      "source": [
        "#Compute loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(13794.8906, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s-vkW_f7jHMv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lower the loss, better the model"
      ]
    },
    {
      "metadata": {
        "id": "wxUokvN5jKbO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compute gradients"
      ]
    },
    {
      "metadata": {
        "id": "KQpv4rRmi584",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6c0ea405-3d0d-4ea5-cb16-bc8d4cf4c30a"
      },
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  5255.7065,   4413.2920,   2956.5833],\n",
            "        [-10967.8496, -13668.3359,  -8070.5430]])\n",
            "tensor([  59.1139, -134.9772])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iUOPJ3ztkslG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Adjust weights and biases"
      ]
    },
    {
      "metadata": {
        "id": "EoolV61ekULC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  w -= w.grad * 1e-5\n",
        "  b -= b.grad * 1e-5\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e8C7iIPzl_1A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* We use torch.no_grad to indicate to PyTorch that we shouldn’t track, calculate or modify gradients while updating the weights and biases.\n",
        "\n",
        "* We multiply the gradients with a really small number called the learning rate\n",
        "\n",
        "*  After we have updated the weights, we reset the gradients to zero by calling .zero_() method. We need to do this, because PyTorch accumulates gradients."
      ]
    },
    {
      "metadata": {
        "id": "ELqHLI8smg7r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2c395504-da39-4a2a-cb4b-d6f28a115b07"
      },
      "cell_type": "code",
      "source": [
        "#After\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.9000,  0.3536,  0.3557],\n",
            "        [ 0.7964, -0.9263, -0.1041]], requires_grad=True)\n",
            "tensor([-0.0787,  0.1045], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nspEI1McmyTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5cafbeea-1d33-42d3-f3fb-396da5bf0d34"
      },
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(9895.0508, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ls2igWaxncON",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train for multiple epochs"
      ]
    },
    {
      "metadata": {
        "id": "tnbBVrTEnbZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        },
        "outputId": "8286367e-edcb-404a-cfc2-28dd63e650cd"
      },
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "  preds = model(inputs)\n",
        "  loss = mse(preds, targets)\n",
        "  print('Loss for Epoch', i, ': ', loss )\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss for Epoch 0 :  tensor(7259.5195, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 1 :  tensor(3776.4258, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 2 :  tensor(3114.2820, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 3 :  tensor(2660.9597, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 4 :  tensor(2348.4485, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 5 :  tensor(2130.9175, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 6 :  tensor(1977.4785, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 7 :  tensor(1867.3170, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 8 :  tensor(1786.4047, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 9 :  tensor(1725.2875, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 10 :  tensor(1677.5925, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 11 :  tensor(1639.0254, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 12 :  tensor(1606.6895, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 13 :  tensor(1578.6335, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 14 :  tensor(1553.5402, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 15 :  tensor(1530.5215, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 16 :  tensor(1508.9778, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 17 :  tensor(1488.5043, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 18 :  tensor(1468.8269, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 19 :  tensor(1449.7601, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 20 :  tensor(1431.1782, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 21 :  tensor(1412.9949, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 22 :  tensor(1395.1519, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 23 :  tensor(1377.6086, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 24 :  tensor(1360.3367, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 25 :  tensor(1343.3167, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 26 :  tensor(1326.5338, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 27 :  tensor(1309.9779, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 28 :  tensor(1293.6409, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 29 :  tensor(1277.5172, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 30 :  tensor(1261.6011, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 31 :  tensor(1245.8887, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 32 :  tensor(1230.3766, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 33 :  tensor(1215.0613, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 34 :  tensor(1199.9402, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 35 :  tensor(1185.0100, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 36 :  tensor(1170.2687, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 37 :  tensor(1155.7131, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 38 :  tensor(1141.3411, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 39 :  tensor(1127.1504, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 40 :  tensor(1113.1388, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 41 :  tensor(1099.3038, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 42 :  tensor(1085.6428, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 43 :  tensor(1072.1542, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 44 :  tensor(1058.8353, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 45 :  tensor(1045.6843, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 46 :  tensor(1032.6992, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 47 :  tensor(1019.8774, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 48 :  tensor(1007.2173, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 49 :  tensor(994.7165, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 50 :  tensor(982.3732, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 51 :  tensor(970.1855, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 52 :  tensor(958.1512, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 53 :  tensor(946.2686, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 54 :  tensor(934.5356, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 55 :  tensor(922.9504, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 56 :  tensor(911.5109, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 57 :  tensor(900.2156, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 58 :  tensor(889.0626, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 59 :  tensor(878.0500, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 60 :  tensor(867.1761, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 61 :  tensor(856.4390, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 62 :  tensor(845.8372, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 63 :  tensor(835.3690, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 64 :  tensor(825.0323, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 65 :  tensor(814.8262, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 66 :  tensor(804.7481, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 67 :  tensor(794.7972, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 68 :  tensor(784.9714, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 69 :  tensor(775.2694, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 70 :  tensor(765.6894, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 71 :  tensor(756.2301, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 72 :  tensor(746.8898, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 73 :  tensor(737.6674, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 74 :  tensor(728.5607, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 75 :  tensor(719.5687, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 76 :  tensor(710.6899, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 77 :  tensor(701.9229, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 78 :  tensor(693.2662, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 79 :  tensor(684.7184, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 80 :  tensor(676.2781, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 81 :  tensor(667.9440, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 82 :  tensor(659.7148, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 83 :  tensor(651.5892, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 84 :  tensor(643.5659, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 85 :  tensor(635.6434, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 86 :  tensor(627.8207, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 87 :  tensor(620.0963, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 88 :  tensor(612.4692, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 89 :  tensor(604.9379, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 90 :  tensor(597.5015, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 91 :  tensor(590.1585, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 92 :  tensor(582.9079, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 93 :  tensor(575.7485, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 94 :  tensor(568.6791, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 95 :  tensor(561.6986, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 96 :  tensor(554.8061, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 97 :  tensor(548.0001, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 98 :  tensor(541.2797, grad_fn=<DivBackward0>)\n",
            "Loss for Epoch 99 :  tensor(534.6439, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rZR5hktjocPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "af8e1cf0-18ba-4b42-a35a-d533c882549a"
      },
      "cell_type": "code",
      "source": [
        "print(preds,'\\n', targets)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 62.9556,  79.1478],\n",
            "        [ 83.9398, 103.7895],\n",
            "        [105.4424, 111.6550],\n",
            "        [ 54.5994,  87.9964],\n",
            "        [ 85.3587,  94.8347]], grad_fn=<AddBackward0>) \n",
            " tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fDhbIwqeo-dL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The prediction are now quite close to the target variables, and we can get even better results by training for a few more epochs."
      ]
    },
    {
      "metadata": {
        "id": "LD2gZAuaowmc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}