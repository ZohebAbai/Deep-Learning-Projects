{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emails_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZohebAbai/Deep-Learning-Projects/blob/master/Emails_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UEJu4FoepAp",
        "colab_type": "text"
      },
      "source": [
        "##Import Mbox data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6IsWbY361qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njtjdGp67Cjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp 'drive/My Drive/Dataset/NLP Assignment Dataset/mbox_dataset/All mail Including Spam and Trash.mbox' ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw192bCSesOE",
        "colab_type": "text"
      },
      "source": [
        "## Extract Emails from it in CSV format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSmqH-w773l5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mailbox\n",
        "import csv\n",
        "from email.header import decode_header\n",
        "#please join tinyurl.com/nlp-tsai for joining the group\n",
        "def get_message(message):\n",
        "    if not message.is_multipart():\n",
        "        return message.get_payload()\n",
        "    content = \"\"\n",
        "    for msg in message.get_payload():\n",
        "        content = content + str(msg.get_payload()) + '\\n'\n",
        "    return content\n",
        "\n",
        "writer = csv.writer(open(\"emails.csv\", \"w\"))\n",
        "writer.writerow(['date', 'from', 'subject', 'content'])\n",
        "\n",
        "for message in mailbox.mbox(\"All mail Including Spam and Trash.mbox\"):\n",
        "    content = get_message(message)\n",
        "    if message['subject'] is not None:\n",
        "        subject, encoding = decode_header(message['subject'])[0]\n",
        "        if encoding == 'utf-8':\n",
        "            subject = subject.decode(encoding)\n",
        "        else:\n",
        "            subject = subject\n",
        "        writer.writerow([message[\"date\"], message[\"from\"].strip('>').split('<')[-1], subject , content])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPf-C6Y1iSF1",
        "colab_type": "text"
      },
      "source": [
        "### Copy the csv file to drive for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zc4ylGT8KEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp 'emails.csv' 'drive/My Drive/Dataset/NLP Assignment Dataset/' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TzNXh-XiYkZ",
        "colab_type": "text"
      },
      "source": [
        "## Explore the csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOV9KOWW8V_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('emails.csv')\n",
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buSZ8IvAcKtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['subs'] = df['from'].map(str) + ' - ' + df['subject'].map(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8V07LJxfHhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.subs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QBYiqFSj8dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMq2aI_Pj_dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK-93uPml8SX",
        "colab_type": "text"
      },
      "source": [
        "**Manually Tag the dataset by downloading it locally**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVGgv9IRivBS",
        "colab_type": "text"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D7oeE0egD_v",
        "colab_type": "code",
        "outputId": "44ac65b0-3947-4d61-f8bc-834c6facda93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# create the tokenizer\n",
        "t = Tokenizer()\n",
        "# fit the tokenizer\n",
        "t.fit_on_texts(df.Subs.values)\n",
        "\n",
        "# summarize what was learned\n",
        "#print(t.word_counts)\n",
        "#print(t.document_count)\n",
        "#print(t.word_index)\n",
        "#print(t.word_docs)\n",
        "\n",
        "# integer encode documents\n",
        "encoded_text = t.texts_to_sequences(df.Subs.values)\n",
        "encoded_text = pad_sequences(encoded_text)\n",
        "print(encoded_text.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 33)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcEDgI-yhQm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_labels = pd.get_dummies(df['tags']).values\n",
        "print(encoded_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvc3IGdWhUr8",
        "colab_type": "text"
      },
      "source": [
        "## Train Valid Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs1CgAqFhWTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(encoded_text, encoded_labels, test_size = 0.20, random_state = 101)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jABmSdzghdIS",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dKZSqzghclX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SpatialDropout1D, Dropout, LSTM, Embedding\n",
        "\n",
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(t.word_index)+1, 1024, input_length = X_train.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(512, dropout=0.2, return_sequences=True))\n",
        "model.add(LSTM(256, dropout=0.1, recurrent_dropout=0.2))\n",
        "model.add(Dense(Y_train.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfsjW_YIhz2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "# define the checkpoint\n",
        "checkpoint = ModelCheckpoint(\"model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "# Fit the Model to data\n",
        "model.fit(X_train, Y_train, epochs=30, batch_size=128, validation_data=(X_test, Y_test), verbose=1, callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ot2kzflh8uq",
        "colab_type": "text"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM1XwpU8h_Gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the model\n",
        "from tensorflow.keras.models import load_model\n",
        "bestmodel = load_model(\"model.h5\")\n",
        "\n",
        "score, acc = bestmodel.evaluate(X_test, Y_test, batch_size=128, verbose=0)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNtXvSTyi58X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "Y_pred = bestmodel.predict_classes(X_test, batch_size = 128)\n",
        "df_test = pd.DataFrame({'true': Y_test.tolist(), 'pred':Y_pred})\n",
        "df_test['true'] = df_test['true'].apply(lambda x: np.argmax(x))\n",
        "print(\"confusion matrix \\n\", confusion_matrix(df_test.true, df_test.pred))\n",
        "print(classification_report(df_test.true, df_test.pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDnkAjVClskx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r 'model.h5' 'drive/My Drive/Dataset/First Run with dataset/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ssc5pYEhlzI9",
        "colab_type": "text"
      },
      "source": [
        "## Load pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhGuxhgijPd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp 'drive/My Drive/Dataset/First Run with dataset/model.h5' ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX1heZSHlyRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the model\n",
        "from tensorflow.keras.models import load_model\n",
        "bestmodel = load_model(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJcoZ7_zm8ix",
        "colab_type": "text"
      },
      "source": [
        "## Predict on a text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up5zOpHWm7TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = ['amazon.in - Invoice of your bill']\n",
        "#vectorizing the text by the pre-fitted tokenizer instance\n",
        "text = t.texts_to_sequences(text)\n",
        "#padding the text to have exactly the same shape as `embedding` input\n",
        "text = pad_sequences(text, maxlen=50, dtype='int32', value=0)\n",
        "#print(text)\n",
        "\n",
        "label = bestmodel.predict(text, batch_size=1, verbose = 1)[0]\n",
        "print(\"Finance\") if(pd.np.argmax(label) == 2) else print(\"MaybeUseful\") if (pd.np.argmax(label) == 1) else print(\"NotFinance\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC-SGtAqqK3p",
        "colab_type": "text"
      },
      "source": [
        "## Save the dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "219OF7_2mkz3",
        "colab_type": "code",
        "outputId": "57af17e2-05c8-4a1e-d183-80f1bced4095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df.tag.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NotFinance     8113\n",
              "Finance         105\n",
              "MaybeUseful      38\n",
              "Name: tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30L2z97oqCk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[df.tag=='Finance'].to_csv('financial_emails.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnQd5jhhqVY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[df.tag=='MaybeUseful'].to_csv('maybeuseful_emails.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCl2ZE-VmOvf",
        "colab_type": "text"
      },
      "source": [
        "**Anonymize the dataset before saving it in drive**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJGx5vMvq3g7",
        "colab_type": "text"
      },
      "source": [
        "## Save the csv files for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_N3SZTzq1c7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp 'financial_emails.csv' 'drive/My Drive/Dataset/NLP Assignment Dataset/' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MSQ2doHq2QH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp 'maybeuseful_emails.csv' 'drive/My Drive/Dataset/NLP Assignment Dataset/' "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}