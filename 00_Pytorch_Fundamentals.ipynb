{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00_Pytorch_Fundamentals.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Fundamentals"
      ],
      "metadata": {
        "id": "7LZ9Zup3b_p5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YblFodkLf7ei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4462532-e3c5-4222-a2f5-34c151391e70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch as pt\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import time\n",
        "print(pt.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Basics\n",
        "\n",
        "A tensor is any n-dimensional array (including a scalar, vector or matrix)."
      ],
      "metadata": {
        "id": "NmLz1rkodnjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar\n",
        "t1 = pt.tensor(4.)\n",
        "\n",
        "# Vector\n",
        "t2 = pt.tensor([1., 2., 3., 4.])\n",
        "\n",
        "# Matrix\n",
        "t3 = pt.tensor([[5.,6], [7,8], [9,10]])\n",
        "\n",
        "# 3D array\n",
        "t4 = pt.tensor([\n",
        "    [[11, 12, 13],\n",
        "    [13, 14, 15]],\n",
        "    [[15, 16, 17],\n",
        "    [17,18,19]]\n",
        "])\n",
        "\n",
        "\n",
        "print(t1.shape,'\\n',t1,'\\n')\n",
        "print(t2.shape,'\\n',t2,'\\n')\n",
        "print(t3.shape,'\\n',t3,'\\n')\n",
        "print(t4.shape,'\\n',t4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leLDAVfodZVX",
        "outputId": "1ad1e76f-fcc1-493d-f478-702f1a80ca09"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([]) \n",
            " tensor(4.) \n",
            "\n",
            "torch.Size([4]) \n",
            " tensor([1., 2., 3., 4.]) \n",
            "\n",
            "torch.Size([3, 2]) \n",
            " tensor([[ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.]]) \n",
            "\n",
            "torch.Size([2, 2, 3]) \n",
            " tensor([[[11, 12, 13],\n",
            "         [13, 14, 15]],\n",
            "\n",
            "        [[15, 16, 17],\n",
            "         [17, 18, 19]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize zeros matrix\n",
        "t1 = pt.zeros(3, 4)\n",
        "\n",
        "# Initialize ones matrix\n",
        "t2 = pt.ones(2,3,4)\n",
        "\n",
        "# Initialize matrix with random values\n",
        "t3 = pt.rand(2, 2, 2, 3)\n",
        "\n",
        "print(t1.shape,'\\n',t1,'\\n')\n",
        "print(t2.shape,'\\n',t2,'\\n')\n",
        "print(t3.shape,'\\n',t3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-7A5lo_frrI",
        "outputId": "cc5bf01a-98ff-4ded-ec89-bbc6a5c5d6f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4]) \n",
            " tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]]) \n",
            "\n",
            "torch.Size([2, 3, 4]) \n",
            " tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]]) \n",
            "\n",
            "torch.Size([2, 2, 2, 3]) \n",
            " tensor([[[[0.3489, 0.3703, 0.4012],\n",
            "          [0.9726, 0.9836, 0.1621]],\n",
            "\n",
            "         [[0.3962, 0.7530, 0.3431],\n",
            "          [0.0732, 0.8721, 0.9327]]],\n",
            "\n",
            "\n",
            "        [[[0.1571, 0.4087, 0.6662],\n",
            "          [0.2543, 0.0422, 0.2589]],\n",
            "\n",
            "         [[0.4714, 0.3234, 0.1258],\n",
            "          [0.0387, 0.4466, 0.1338]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interoperability with Numpy"
      ],
      "metadata": {
        "id": "s3HntqqZidmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Python List\n",
        "python_list = [1, 2]\n",
        "\n",
        "# Create a numpy array from python list\n",
        "numpy_array = np.array(python_list)\n",
        "\n",
        "# Create a torch Tensor from python list\n",
        "tensor_from_list = pt.tensor(python_list)\n",
        "\n",
        "# Create a torch Tensor from Numpy array\n",
        "tensor_from_array = pt.tensor(numpy_array)\n",
        "\n",
        "# Another way to create a torch Tensor from Numpy array (share same storage)\n",
        "tensor_from_array_v2 = pt.from_numpy(numpy_array)\n",
        "\n",
        "# Convert torch tensor to numpy array\n",
        "array_from_tensor = tensor_from_array.numpy()\n",
        "\n",
        "print('List:   ', python_list)\n",
        "print('Array:  ', numpy_array)\n",
        "print('Tensor: ', tensor_from_list)\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Tensor: ', tensor_from_array_v2)\n",
        "print('Array:  ', array_from_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx6yBPs0h3yF",
        "outputId": "61ac7f03-a534-4a0b-d817-9522e5ef1138"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List:    [1, 2]\n",
            "Array:   [1 2]\n",
            "Tensor:  tensor([1, 2])\n",
            "Tensor:  tensor([1, 2])\n",
            "Tensor:  tensor([1, 2])\n",
            "Array:   [1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have two different ways to create tensor from its NumPy counterpart: \n",
        "- `torch.Tensor`: one copies memory and \n",
        "- `torch.from_numpy`: one shares the same underlying storage."
      ],
      "metadata": {
        "id": "KWl9_9whmpF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array[0] = 10\n",
        "\n",
        "print('Changed Array:  ', numpy_array)\n",
        "print('Tensor copy memory: ', tensor_from_array)\n",
        "print('Tensor sharing memory: ', tensor_from_array_v2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idWeY__NmB4Z",
        "outputId": "43929ee3-b7c5-46bd-ce77-73e47233d0e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed Array:   [10  2]\n",
            "Tensor copy memory:  tensor([1, 2])\n",
            "Tensor sharing memory:  tensor([10,  2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Types\n",
        "\n",
        "The basic data type of all Deep Learning-related operations is float, but sometimes you may need something else. Pytorch support different number types for its tensors the same way NumPy does it - by specifying the data type on tensor creation or via casting."
      ],
      "metadata": {
        "id": "Wk5i32jLpHbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = pt.zeros(2, 2)\n",
        "print('Tensor with default type: \\n', tensor)\n",
        "\n",
        "tensor1 = pt.zeros(2, 2, dtype=pt.float16)\n",
        "print('Tensor with 16-bit float: \\n', tensor1)\n",
        "\n",
        "tensor2 = pt.zeros(2, 2, dtype=pt.int16)\n",
        "print('Tensor with integers: \\n', tensor2)\n",
        "\n",
        "tensor3 = tensor.type(pt.bool)\n",
        "print('Tensor with boolean data: \\n', tensor3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0PIiLsInMst",
        "outputId": "110a1430-56c2-41ad-c58e-89edfbb18640"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor with default type: \n",
            " tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "Tensor with 16-bit float: \n",
            " tensor([[0., 0.],\n",
            "        [0., 0.]], dtype=torch.float16)\n",
            "Tensor with integers: \n",
            " tensor([[0, 0],\n",
            "        [0, 0]], dtype=torch.int16)\n",
            "Tensor with boolean data: \n",
            " tensor([[False, False],\n",
            "        [False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing"
      ],
      "metadata": {
        "id": "vTmXN2g7r4sB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = pt.rand((5, 3))\n",
        "rows = pt.arange(0, 2)\n",
        "print(a)\n",
        "print(rows)\n",
        "print(a[rows])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8uI4e-osRQo",
        "outputId": "8d2376a8-2821-4bc9-cdec-659016893f8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1411, 0.1401, 0.1087],\n",
            "        [0.2660, 0.1236, 0.6172],\n",
            "        [0.4185, 0.1392, 0.4104],\n",
            "        [0.5480, 0.8486, 0.9430],\n",
            "        [0.6654, 0.0826, 0.0039]])\n",
            "tensor([0, 1])\n",
            "tensor([[0.1411, 0.1401, 0.1087],\n",
            "        [0.2660, 0.1236, 0.6172]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = pt.zeros(3, 2)\n",
        "b = pt.ones(3, 2)\n",
        "print(pt.cat((a, b), dim=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTx4arbnr7fJ",
        "outputId": "1538f37a-2622-4207-c163-d425573abc95"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Operations\n",
        "\n",
        "### Autograd\n",
        "Pytorch supports automatic differentiation. The module which implements this is called AutoGrad. It calculates the gradients and keeps track in forward and backward passes. For primitive tensors, you need to enable or disable it using the required_grad flag. But, for advanced tensors, it is enabled by default"
      ],
      "metadata": {
        "id": "VbDHQ-6IrXWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = pt.tensor(3.)\n",
        "w = pt.tensor(4., requires_grad=True)\n",
        "b = pt.tensor(5., requires_grad=True)\n",
        "y = w * x + b\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQGNUqO0qMkL",
        "outputId": "ed0c0248-914a-4fff-8828-a026b03c2118"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(17., grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, y is a tensor with the value 3 * 4 + 5 = 17. \n",
        "\n",
        "What makes PyTorch special is that we can automatically compute the derivative of y w.r.t. the tensors that have requires_grad set to True i.e. w and b. To compute the derivatives, we can call the .backward method on our result y."
      ],
      "metadata": {
        "id": "f6RQFVDvw8ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute derivatives\n",
        "y.backward()\n",
        "\n",
        "#Display the gradients\n",
        "print('dy/dx:', x.grad)\n",
        "print('dy/dw:', w.grad)\n",
        "print('dy/db:', b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA1m8Rllw2kI",
        "outputId": "f5fde7c9-4812-47a4-e6b0-1ffd285bb14a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx: None\n",
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Disabling Autograd**\n",
        "\n",
        "We don't need to compute gradients for all the variables that are involved in the pipeline. The Pytorch API provides two ways to disable autograd.\n",
        "\n",
        "- `detach` returns a copy of the tensor with autograd disabled. This copy is built on the same memory as the original tensor.\n",
        "- `torch.no_grad()`: It is a context manager that allows you to guard a series of operations from autograd without creating new tensors."
      ],
      "metadata": {
        "id": "M9m0XfSRx-Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = pt.rand((3, 5), requires_grad=True)\n",
        "with pt.no_grad():\n",
        "    result = a * 5\n",
        "mean_result = result.sum()\n",
        "\n",
        "# it would give error as we had disabled autograd\n",
        "try:\n",
        "    mean_result.backward()\n",
        "except RuntimeError:\n",
        "    print(\"Auto grad is disabled!!\")\n",
        "print(\"gradient of a:\", a.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf-rpPy4xUC4",
        "outputId": "a9869803-32eb-4193-fdde-481c3c96cdfd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Auto grad is disabled!!\n",
            "gradient of a: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping a tensor \n",
        "Its a frequently used operation. We can change the shape of a tensor without the memory copying overhead. There are two methods for that: `reshape` and `view`.\n",
        "\n",
        "The difference is the following:\n",
        "\n",
        "- `view` shares the same memory with the original tensor\n",
        "- `reshape` tries to reuse the memory, if not then creates a copy\n",
        "\n",
        "Let's see with the help of an example:"
      ],
      "metadata": {
        "id": "JVTPEsea3NnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orig = pt.rand(2, 3, 4)\n",
        "print('Pointer to data: ', orig.data_ptr())\n",
        "print('Shape: ', orig.shape)\n",
        "print('Original data:\\n', orig)\n",
        "\n",
        "view = orig.view(3, 2, 4)\n",
        "print('Viewed tensor - pointer to data', view.data_ptr())\n",
        "print('Viewed tensor shape ', view.shape)\n",
        "print('Viewed data:\\n', view)\n",
        "\n",
        "reshaped = orig.reshape(24)\n",
        "print('Reshaped tensor - pointer to data', reshaped.data_ptr())\n",
        "print('Reshaped tensor shape ', reshaped.shape)\n",
        "print('Reshaped data:\\n', reshaped)\n",
        "\n",
        "assert np.all(np.equal(view.numpy().flat, reshaped.numpy().flat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQeU2MipzGsu",
        "outputId": "0274bcd1-23b7-4192-f39f-6da2dcb883f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pointer to data:  94547708508544\n",
            "Shape:  torch.Size([2, 3, 4])\n",
            "Original data:\n",
            " tensor([[[0.1461, 0.5134, 0.2296, 0.8983],\n",
            "         [0.5029, 0.7537, 0.3057, 0.9972],\n",
            "         [0.3054, 0.2991, 0.7453, 0.2028]],\n",
            "\n",
            "        [[0.6805, 0.9405, 0.1137, 0.1345],\n",
            "         [0.8513, 0.1525, 0.6227, 0.4754],\n",
            "         [0.3267, 0.3876, 0.9068, 0.6108]]])\n",
            "Viewed tensor - pointer to data 94547708508544\n",
            "Viewed tensor shape  torch.Size([3, 2, 4])\n",
            "Viewed data:\n",
            " tensor([[[0.1461, 0.5134, 0.2296, 0.8983],\n",
            "         [0.5029, 0.7537, 0.3057, 0.9972]],\n",
            "\n",
            "        [[0.3054, 0.2991, 0.7453, 0.2028],\n",
            "         [0.6805, 0.9405, 0.1137, 0.1345]],\n",
            "\n",
            "        [[0.8513, 0.1525, 0.6227, 0.4754],\n",
            "         [0.3267, 0.3876, 0.9068, 0.6108]]])\n",
            "Reshaped tensor - pointer to data 94547708508544\n",
            "Reshaped tensor shape  torch.Size([24])\n",
            "Reshaped data:\n",
            " tensor([0.1461, 0.5134, 0.2296, 0.8983, 0.5029, 0.7537, 0.3057, 0.9972, 0.3054,\n",
            "        0.2991, 0.7453, 0.2028, 0.6805, 0.9405, 0.1137, 0.1345, 0.8513, 0.1525,\n",
            "        0.6227, 0.4754, 0.3267, 0.3876, 0.9068, 0.6108])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image View"
      ],
      "metadata": {
        "id": "9lfVU8ipCLNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a black image\n",
        "image = pt.zeros(size=(3, 256, 256), dtype=pt.int)\n",
        "\n",
        "# Leave the borders and make the rest of the image Green\n",
        "image[1, 18:256 - 18, 18:256 - 18] = 255\n",
        "\n",
        "# Create a mask of the same size\n",
        "mask = pt.zeros(size=(256, 256), dtype=pt.bool)\n",
        "print(f\"mask shape before: {mask.shape}\")\n",
        "\n",
        "# Assuming the green region in the original image is the Region of interest, \n",
        "# change the mask to white for that area\n",
        "mask[18:256 - 18, 18:256 - 18] = 1\n",
        "\n",
        "# Create a view of the mask with the same dimensions as the original image\n",
        "mask_expanded = mask.expand_as(image)\n",
        "print(f\"mask shape after: {mask_expanded.shape}\")\n",
        "\n",
        "mask_np = mask_expanded.numpy().transpose(1, 2, 0) * 255\n",
        "image_np = image.numpy().transpose(1, 2, 0)\n",
        "\n",
        "fig, ax = plt.subplots(1, 3)\n",
        "ax[0].imshow(image_np)\n",
        "ax[1].imshow(mask_np)\n",
        "\n",
        "image[mask_expanded] -= 128\n",
        "image.clamp_(0, 255)\n",
        "ax[2].imshow(image_np)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "BIU_m7R9_MFu",
        "outputId": "0449e348-4fe8-402a-90da-cbe6cd40d44b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask shape before: torch.Size([256, 256])\n",
            "mask shape after: torch.Size([3, 256, 256])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Regression Model Training on GPU"
      ],
      "metadata": {
        "id": "WSddgnmaG0A_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FeedForward Model"
      ],
      "metadata": {
        "id": "aDMqwS1mNDts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                  [91, 88, 64],\n",
        "                  [87, 134, 58],\n",
        "                  [102, 43, 37],\n",
        "                  [69, 96, 70]], dtype= 'float32')\n",
        "\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70],\n",
        "                   [81, 101],\n",
        "                   [119, 133],\n",
        "                   [22, 37],\n",
        "                   [103, 119]], dtype= 'float32')\n",
        "\n",
        "# device\n",
        "gpu = pt.device(\"cuda\")\n",
        "\n",
        "# Convert inputa and targets to tensors\n",
        "inputs = pt.from_numpy(inputs).to(\"cuda\")\n",
        "targets = pt.from_numpy(targets).to(\"cuda\")\n",
        "print(f\"Input shape: {inputs.shape}\")\n",
        "print(f\"Targets shape: {targets.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2oO-f6sDR2N",
        "outputId": "224b3e2f-36ca-425f-af65-4d0440923ae6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([5, 3])\n",
            "Targets shape: torch.Size([5, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.randn` creates a tensor of the given shape, with elements picked randomly from a normal distribution with mean 0 and standard deviation 1."
      ],
      "metadata": {
        "id": "wNbpPy_hImtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights and biases\n",
        "w = pt.randn(targets.shape[1], inputs.shape[1], device=gpu, requires_grad= True)\n",
        "b = pt.randn(targets.shape[1], device=gpu, requires_grad= True)\n",
        "print(f\"Weights: \\n {w}\")\n",
        "print(f\"Biases: {b}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scvdtvqsIIa9",
        "outputId": "352e723d-a232-4fa0-8a1d-1280b9a71129"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: \n",
            " tensor([[ 0.9668, -0.7833, -0.8931],\n",
            "        [ 0.4536,  0.4343, -0.5132]], device='cuda:0', requires_grad=True)\n",
            "Biases: tensor([-2.3648, -1.0439], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "# Linear Regression\n",
        "def model(x):\n",
        "  return x @ w.t() + b \n",
        "\n",
        "# Predictions\n",
        "preds = model(inputs)\n",
        "\n",
        "# Let's define a metric to understand how worse out predictions are\n",
        "# Mean Squared Error loss function\n",
        "def mse(t1, t2):\n",
        "  diff = t1-t2\n",
        "  return pt.sum(diff*diff) / diff.numel()\n",
        "#.numel method returns the number of elements in a tensor.\n",
        "\n",
        "# Compute loss\n",
        "loss = mse(preds, targets)\n",
        "print(f\"Loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAVW6DWgJvXz",
        "outputId": "bd6bb0a1-5ea5-47fe-d31d-f677d1f8f25d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 10508.916015625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thereâ€™s a huge difference between the predictions of our model, and the actual values of the target variables. Let's try to reduce the loss by adjusting weights and biases."
      ],
      "metadata": {
        "id": "DbxgAAlYMdt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backpropagation (for one epoch)\n"
      ],
      "metadata": {
        "id": "QLza0UyHNM7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Gradients\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slhwx0g_MVb2",
        "outputId": "865af5db-5a48-456f-aa37-9ec967cfe04c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -9015.3418, -11712.8945,  -6895.2485],\n",
            "        [ -3593.9470,  -4686.7974,  -2845.1836]], device='cuda:0')\n",
            "tensor([-112.5968,  -45.5010], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust weights and biases\n",
        "learning_rate = 1e-04\n",
        "with pt.no_grad():\n",
        "    w -= w.grad * learning_rate\n",
        "    b -= b.grad * learning_rate\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "# After we have updated the weights, we reset the gradients to zero by calling .zero_() method. \n",
        "# We need to do this, because PyTorch accumulates gradients.\n",
        "\n",
        "print(f\"Weights: \\n {w}\")\n",
        "print(f\"Biases: {b}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azXdbdNNNyT7",
        "outputId": "cedc3b24-8d2b-4df2-ca45-19dca2a336c9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: \n",
            " tensor([[ 1.8683,  0.3880, -0.2035],\n",
            "        [ 0.8130,  0.9030, -0.2287]], device='cuda:0', requires_grad=True)\n",
            "Biases: tensor([-2.3536, -1.0393], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "preds = model(inputs)\n",
        "\n",
        "# Compute loss\n",
        "loss = mse(preds, targets)\n",
        "print(f\"Loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5dIT6t9O7S6",
        "outputId": "52e24150-97ba-47bb-ef74-de95b1a751b3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 7079.55712890625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss reduced drastically, isn't it? This was for one epoch (a complete feedforward - backpropagation cycle). Let's  repeat the same for multiple epoch untill we reach a satisfied value for loss."
      ],
      "metadata": {
        "id": "G9-vzaH_PesG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training for multiple epochs"
      ],
      "metadata": {
        "id": "6AdsdcWwP87Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "for i in range(100):\n",
        "  preds = model(inputs)\n",
        "  loss = mse(preds, targets)\n",
        "  print(f\"Loss for Epoch {i} : {loss}\")\n",
        "  loss.backward()\n",
        "  with pt.no_grad():\n",
        "    w -= w.grad * learning_rate\n",
        "    b -= b.grad * learning_rate\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "print(f\"Total time taken: {time.time()- start}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIZ7u4Z0Paw5",
        "outputId": "7db6f654-6ec6-4451-9422-aa7bed20efeb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Epoch 0 : 7079.55712890625\n",
            "Loss for Epoch 1 : 4877.60791015625\n",
            "Loss for Epoch 2 : 3450.356201171875\n",
            "Loss for Epoch 3 : 2513.754638671875\n",
            "Loss for Epoch 4 : 1889.3671875\n",
            "Loss for Epoch 5 : 1464.9224853515625\n",
            "Loss for Epoch 6 : 1169.6171875\n",
            "Loss for Epoch 7 : 958.6625366210938\n",
            "Loss for Epoch 8 : 803.6026611328125\n",
            "Loss for Epoch 9 : 686.2548217773438\n",
            "Loss for Epoch 10 : 594.9085693359375\n",
            "Loss for Epoch 11 : 521.9439697265625\n",
            "Loss for Epoch 12 : 462.3360900878906\n",
            "Loss for Epoch 13 : 412.71539306640625\n",
            "Loss for Epoch 14 : 370.77490234375\n",
            "Loss for Epoch 15 : 334.8973693847656\n",
            "Loss for Epoch 16 : 303.91839599609375\n",
            "Loss for Epoch 17 : 276.9750061035156\n",
            "Loss for Epoch 18 : 253.40966796875\n",
            "Loss for Epoch 19 : 232.7078857421875\n",
            "Loss for Epoch 20 : 214.4571533203125\n",
            "Loss for Epoch 21 : 198.3195343017578\n",
            "Loss for Epoch 22 : 184.0139923095703\n",
            "Loss for Epoch 23 : 171.30357360839844\n",
            "Loss for Epoch 24 : 159.98594665527344\n",
            "Loss for Epoch 25 : 149.88743591308594\n",
            "Loss for Epoch 26 : 140.85797119140625\n",
            "Loss for Epoch 27 : 132.76718139648438\n",
            "Loss for Epoch 28 : 125.50178527832031\n",
            "Loss for Epoch 29 : 118.9625244140625\n",
            "Loss for Epoch 30 : 113.0628662109375\n",
            "Loss for Epoch 31 : 107.7271728515625\n",
            "Loss for Epoch 32 : 102.888916015625\n",
            "Loss for Epoch 33 : 98.48973846435547\n",
            "Loss for Epoch 34 : 94.47871398925781\n",
            "Loss for Epoch 35 : 90.8109359741211\n",
            "Loss for Epoch 36 : 87.4471206665039\n",
            "Loss for Epoch 37 : 84.35259246826172\n",
            "Loss for Epoch 38 : 81.49686431884766\n",
            "Loss for Epoch 39 : 78.8534927368164\n",
            "Loss for Epoch 40 : 76.39875793457031\n",
            "Loss for Epoch 41 : 74.1121826171875\n",
            "Loss for Epoch 42 : 71.9755630493164\n",
            "Loss for Epoch 43 : 69.97289276123047\n",
            "Loss for Epoch 44 : 68.09017181396484\n",
            "Loss for Epoch 45 : 66.31499481201172\n",
            "Loss for Epoch 46 : 64.63643646240234\n",
            "Loss for Epoch 47 : 63.04502487182617\n",
            "Loss for Epoch 48 : 61.53208541870117\n",
            "Loss for Epoch 49 : 60.09029006958008\n",
            "Loss for Epoch 50 : 58.71306228637695\n",
            "Loss for Epoch 51 : 57.39448928833008\n",
            "Loss for Epoch 52 : 56.12944412231445\n",
            "Loss for Epoch 53 : 54.91340255737305\n",
            "Loss for Epoch 54 : 53.74223709106445\n",
            "Loss for Epoch 55 : 52.61249923706055\n",
            "Loss for Epoch 56 : 51.520904541015625\n",
            "Loss for Epoch 57 : 50.464717864990234\n",
            "Loss for Epoch 58 : 49.44139099121094\n",
            "Loss for Epoch 59 : 48.4487190246582\n",
            "Loss for Epoch 60 : 47.48466110229492\n",
            "Loss for Epoch 61 : 46.547481536865234\n",
            "Loss for Epoch 62 : 45.63555908203125\n",
            "Loss for Epoch 63 : 44.74741744995117\n",
            "Loss for Epoch 64 : 43.881893157958984\n",
            "Loss for Epoch 65 : 43.03774642944336\n",
            "Loss for Epoch 66 : 42.21384048461914\n",
            "Loss for Epoch 67 : 41.409358978271484\n",
            "Loss for Epoch 68 : 40.623451232910156\n",
            "Loss for Epoch 69 : 39.855228424072266\n",
            "Loss for Epoch 70 : 39.10407638549805\n",
            "Loss for Epoch 71 : 38.36928176879883\n",
            "Loss for Epoch 72 : 37.65027618408203\n",
            "Loss for Epoch 73 : 36.94647216796875\n",
            "Loss for Epoch 74 : 36.257362365722656\n",
            "Loss for Epoch 75 : 35.582557678222656\n",
            "Loss for Epoch 76 : 34.92147445678711\n",
            "Loss for Epoch 77 : 34.273834228515625\n",
            "Loss for Epoch 78 : 33.63910675048828\n",
            "Loss for Epoch 79 : 33.01710891723633\n",
            "Loss for Epoch 80 : 32.40735626220703\n",
            "Loss for Epoch 81 : 31.809661865234375\n",
            "Loss for Epoch 82 : 31.223520278930664\n",
            "Loss for Epoch 83 : 30.64887809753418\n",
            "Loss for Epoch 84 : 30.08534049987793\n",
            "Loss for Epoch 85 : 29.53260612487793\n",
            "Loss for Epoch 86 : 28.99054527282715\n",
            "Loss for Epoch 87 : 28.458820343017578\n",
            "Loss for Epoch 88 : 27.937286376953125\n",
            "Loss for Epoch 89 : 27.425613403320312\n",
            "Loss for Epoch 90 : 26.923681259155273\n",
            "Loss for Epoch 91 : 26.43123435974121\n",
            "Loss for Epoch 92 : 25.948074340820312\n",
            "Loss for Epoch 93 : 25.474096298217773\n",
            "Loss for Epoch 94 : 25.008996963500977\n",
            "Loss for Epoch 95 : 24.552637100219727\n",
            "Loss for Epoch 96 : 24.104894638061523\n",
            "Loss for Epoch 97 : 23.665496826171875\n",
            "Loss for Epoch 98 : 23.23434066772461\n",
            "Loss for Epoch 99 : 22.811315536499023\n",
            "Total time taken: 0.13777804374694824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Target values :\\n {targets}\")\n",
        "print(f\"Prediction values :\\n {preds}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NEpbaGYQUDl",
        "outputId": "0040ef58-0125-4b73-d4f3-0127760ac9cb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target values :\n",
            " tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]], device='cuda:0')\n",
            "Prediction values :\n",
            " tensor([[ 57.1626,  70.5689],\n",
            "        [ 79.3783,  97.2266],\n",
            "        [125.1230, 140.3692],\n",
            "        [ 23.0836,  39.1749],\n",
            "        [ 95.3643, 111.6812]], device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wow! So Close. Our model has been trained well.**"
      ],
      "metadata": {
        "id": "zon_L5kRQ6Dv"
      }
    }
  ]
}