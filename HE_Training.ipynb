{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8267077d-151b-41ab-8900-b6b19dd9259f",
   "metadata": {},
   "source": [
    "# Training a Logistic Regression Model on encrypted training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "599b2ff9-0363-476e-862f-9949b4f03312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "# those are optional and are not necessary for training\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a767130-1278-4e00-a23c-b0d8d40b106c",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "We now prepare the training and test data, the dataset was downloaded from Kaggle. [This dataset](https://www.kaggle.com/datasets/naveengowda16/logistic-regression-heart-disease-prediction) provides patients' information along with a 10-year risk of future coronary heart disease (CHD) as a label, and the goal is to build a model that can predict this 10-year CHD risk based on patients' information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a8b816-b708-4e72-8587-71b4a36bc1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"framingham.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5a67a31-ee64-40d4-9015-a59137379fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Data summary #############\n",
      "x_train has shape: torch.Size([780, 9])\n",
      "y_train has shape: torch.Size([780, 1])\n",
      "x_test has shape: torch.Size([334, 9])\n",
      "y_test has shape: torch.Size([334, 1])\n",
      "#######################################\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(73)\n",
    "random.seed(73)\n",
    "\n",
    "def split_train_test(x, y, test_ratio=0.3):\n",
    "    idxs = [i for i in range(len(x))]\n",
    "    random.shuffle(idxs)\n",
    "    # delimiter between test and train data\n",
    "    delim = int(len(x) * test_ratio)\n",
    "    test_idxs, train_idxs = idxs[:delim], idxs[delim:]\n",
    "    return x[train_idxs], y[train_idxs], x[test_idxs], y[test_idxs]\n",
    "            \n",
    "def heart_disease_data():    \n",
    "    data = pd.read_csv(\"framingham.csv\")\n",
    "    # drop rows with missing values\n",
    "    data = data.dropna()\n",
    "    # drop some features\n",
    "    data = data.drop(columns=[\"education\", \"currentSmoker\", \"BPMeds\", \"diabetes\", \"diaBP\", \"BMI\"])\n",
    "    # balance data\n",
    "    grouped = data.groupby('TenYearCHD')\n",
    "    data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n",
    "    # extract labels\n",
    "    y = torch.tensor(data[\"TenYearCHD\"].values).float().unsqueeze(1)\n",
    "    data = data.drop(labels=\"TenYearCHD\", axis='columns')\n",
    "    # standardize data\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    x = torch.tensor(data.values).float()\n",
    "    return split_train_test(x, y)\n",
    "\n",
    "x_train, y_train, x_test, y_test = heart_disease_data()\n",
    "\n",
    "print(\"############# Data summary #############\")\n",
    "print(f\"x_train has shape: {x_train.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"x_test has shape: {x_test.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")\n",
    "print(\"#######################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc2c58-7b6e-4add-b519-d3bfd65d7f72",
   "metadata": {},
   "source": [
    "## Training an Simple Logistic Regression Model on plain data\n",
    "\n",
    "We will start by training a logistic regression model (without any encryption), which can be viewed as a single layer neural network with a single node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73aa75d9-0728-46ff-9219-8db90985e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr = torch.nn.Linear(n_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.lr(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbe554b4-da57-4313-a5e4-cfa12f807bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = x_train.shape[1]\n",
    "model = LR(n_features)\n",
    "\n",
    "# use gradient descent with a learning_rate=1\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "# use Binary Cross Entropy Loss\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b026b80-a491-4ac7-8347-b93e9c7f36d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution on plain data:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgDklEQVR4nO3de3Bc53nf8e+DO4gbQQIkQIIXUKIutC3ZMiPLl8oeS7Yl15ESO06oTlpf0lHdVGNnkqaW61TjKtPJ2B57MpkqdRTHkzSTVJbt2GFiOorkW2M3VkTJEiWKpAjxIgIEiQtBXInFZZ/+sXug1RIgFsDunrNnf58Zjnb3vLvn4cHqh5fvec95zd0REZHSVxF2ASIikh8KdBGRmFCgi4jEhAJdRCQmFOgiIjFRFdaO29rafOfOnWHtXkSkJD399NND7t6+2LbQAn3nzp0cPHgwrN2LiJQkMzu91DYNuYiIxIQCXUQkJhToIiIxoUAXEYkJBbqISEwo0EVEYkKBLiISE6HNQxeJCnfn7w71M59McveNW6mosLBLElkVBbqUvf/5gx6+9PhLABw7N8H9d14XckUiq6MhFylrF6dmeOhHPdz5+g4++KatfPWfTnB+bDrsskRWRYEuZe2bT/cyPZvkU7fv5pO37Wbena8/dSbsskRWRYEuZe3xF89zXUcT13U0s7Otgb07Wnns8LmwyxJZFQW6lK3RqVkOnh7h9us3L7x2+/WbOXx2jP7RSyFWJrI6CnQpW0+eHGY+6bzz2lfvRPr2q9sA+JeTF8IqS2TVFOhStn5+5iLVlcYbtrYsvHZdRxPraip5+vRIiJWJrI4CXcrWz18Z4frOZuqqKxdeq6qs4KbtrRw8pUCX0qNAl7I0N5/kUO8ob9q2/rJtN25r4dj5cRJz88UvTGQNFOhSlk4MTTI1M8+NiwT69Z3NzCed4+cnil+YyBoo0KUsHTs3DsC1HU2Xbbu+sxmAI/1jRa1JZK0U6FKWjp8fp8LgqvbGy7bt3NhAXXUFR9OhL1IqFOhSll46P8GOjQ2vOSEaqKwwrt3cpB66lBwFupSllwbG2b3p8t55YPfmJnoGNIYupUWBLmUnMTfP6eEprtl8+fh5oLutgYHxBBOJuSJWJrI2OQW6md1hZsfMrMfM7l9k+0fNbNDMnk3/+ff5L1UkP04OTTKfdHZvXrqHvqutAYBTQ5PFKktkzZYNdDOrBB4C7gT2APeY2Z5Fmn7d3d+Y/vPVPNcpkjenhqYA2NW2dKB3t6cC/aQCXUpILj30m4Eedz/h7jPAI8DdhS1LpHBeuZAK6e0b1y3ZZudGBbqUnlwCfSuQeYPo3vRr2T5kZofM7Jtmtm2xDzKze83soJkdHBwcXEW5Imt3eniKlvpqWuqrl2xTV13JlpY6BbqUlHydFP07YKe73wA8DvzFYo3c/WF33+vue9vb2xdrIlJwr1yYYscVeueB7vYGTijQpYTkEuh9QGaPuyv92gJ3H3b3RPrpV4E356c8kfx75cIU2zcsH+g7NzZweliBLqUjl0B/CthtZt1mVgPsA/ZnNjCzzoyndwFH8leiSP7MzSfpG7mUUw+9q3UdF6dmNXVRSsayge7uc8B9wGOkgvpRdz9sZg+a2V3pZp80s8Nm9hzwSeCjhSpYZC36R6eZS3pOPfSu1noA+ka0epGUhqpcGrn7AeBA1msPZDz+DPCZ/JYmkn+nh1NTFrdvaFi2bRDovSNTi97ESyRqdKWolJVXLqQDPYchl60Lga4eupQGBbqUlb6LU1RWGB3Ndcu2bW+spbaqgr6LCnQpDQp0KSv9F6fpaK6jssKWbWtmbG2tp3dkqgiViaydAl3KytnRS3S2LN87D3S1rtOQi5QMBbqUlf7Rabasr8+5fVdrvQJdSoYCXcpGMun0X5ymc33uPfSt6+u5MDnD1Izmokv0KdClbAxPzjAzn2RLy8p66ABnL04XqiyRvFGgS9noH00NnaxkDH1zejbM+TEFukSfAl3KRtDLXskYehD+/aMKdIk+BbqUjbPp+eQrCfSgh35uVCdGJfoU6FI2+kcvUVtVQeu6pe+Dnq2uupLWddWc05CLlAAFupSNs+kpi2bLX1SUaXNzHec05CIlQIEuZaP/4iW2rGDKYqCzpU49dCkJCnQpG/2j03SuYMpioKNFPXQpDQp0KQvzSWdgPJHTTbmydTTXMzQxw8xcsgCVieSPAl3KwsjUDPNJZ1Nz7Yrf29GSeo/mokvUKdClLAyMpZa8bW9cTaCnhmkU6BJ1CnQpC4MTqUBfVQ+9WRcXSWlQoEtZGEj3rtsbVzGG3qLL/6U0KNClLAQ99PamlffQm+uqqK+uVA9dIk+BLmVhYCxBU20V9TWVK36vmaWmLqqHLhGnQJeyMDiRoH0V4+eB9qZaBscTeaxIJP8U6FIWBscSq5rhEtikQJcSoECXsjA4kWDTKi4qCrQ31S6cWBWJKgW6lIWBsek19tDrmJyZZzKhpegkuhToEnuTiTkmZ+ZXNQc9sCk9O0bDLhJlCnSJvSCE19JDD6Y7DijQJcJyCnQzu8PMjplZj5ndf4V2HzIzN7O9+StRZG3WcpVoIHjvwLjG0SW6lg10M6sEHgLuBPYA95jZnkXaNQGfAp7Md5Eia7FwH5dVXFQU2NSUOqGqIReJslx66DcDPe5+wt1ngEeAuxdp9/vA5wF1YSRSBseDy/5XH+jr66uprjQNuUik5RLoW4EzGc97068tMLObgG3u/t0rfZCZ3WtmB83s4ODg4IqLFVmNgfEEVRVG67qaVX9GRYXR1li70NsXiaI1nxQ1swrgy8DvLNfW3R92973uvre9vX2tuxbJyeB4grbGWioqVraWaLZNTbUaQ5dIyyXQ+4BtGc+70q8FmoDXAz8ys1PALcB+nRiVqEhdVLT64ZZAe1OdxtAl0nIJ9KeA3WbWbWY1wD5gf7DR3Ufdvc3dd7r7TuBnwF3ufrAgFYus0MAaL/sPbGrW5f8SbcsGurvPAfcBjwFHgEfd/bCZPWhmdxW6QJG1ylsPvbGW4ckZZue1tqhEU1Uujdz9AHAg67UHlmj7rrWXJZIf80lneCJ/PXSA4YmZhUUvRKJEV4pKrA1PJkg6tK/hxlyBYC66ToxKVCnQJdbWsjh0tuB+Lpq6KFGlQJdYy8dl/wHdz0WiToEusTaYxx56W6PuuCjRpkCXWFvL4tDZaqoq2NBQozF0iSwFusTawNg0zXVV1FWvfHHoxaSuFlUPXaJJgS6xNjiRyEvvPNCuQJcIU6BLrA2MJRamG+ZDe1MtQwp0iSgFusRaIXrog+MJ3D1vnymSLwp0iS13T/fQ8xfom5rqmJlPMnZJi0VL9CjQJbYmZ+a5NDuf9x466GpRiSYFusTWwFgqdPNxUVGgXXPRJcIU6BJbQei2N+bvpOiri0Ur0CV6FOgSW0Ho5rWH3qQeukSXAl1i69Ueev4Cvam2itqqioUrUEWiRIEusTU4kaC60li/rjpvn2lmbGquXRifF4kSBbrEVrD0nNnaFofO1t5Yqx66RJICXWJrcCKRl4Utsm3SYtESUQp0ia2Bsem8jp8HdD8XiSoFusTWUJ4Wh87W3lTLxalZEnPzef9skbVQoEsszc0nGZ6cKUgPPbiVwNDETN4/W2QtFOgSS8OTM7jnZ2GLbJqLLlGlQJdYChZyzueNuQLB7XgV6BI1CnSJpcGJ1DzxQvbQdYMuiRoFusTSQg+9ANMWNzbWYKYeukSPAl1iKQjbtsaavH92dWUFG9bVaOqiRI4CXWJpYDzB+nXV1FblZ3HobMHKRSJRklOgm9kdZnbMzHrM7P5Ftn/CzJ43s2fN7Cdmtif/pYrkbnA8UZApiwEFukTRsoFuZpXAQ8CdwB7gnkUC+6/d/Q3u/kbgC8CX812oyEoMjE8X5KKigAJdoiiXHvrNQI+7n3D3GeAR4O7MBu4+lvG0AdAKuhKqwYni9NC1WLRESVUObbYCZzKe9wJvyW5kZv8J+G2gBnj3Yh9kZvcC9wJs3759pbWK5GRhcegCzHAJZC4W3ZLH2/OKrEXeToq6+0PufhXwaeD3lmjzsLvvdfe97e3t+dq1yGuMJ+ZIzCUL3kMHzUWXaMkl0PuAbRnPu9KvLeUR4JfWUJPImgRz0AtxUVFAi0VLFOUS6E8Bu82s28xqgH3A/swGZrY74+m/Bo7nr0SRlQl6zYW47D+gxaIlipYdQ3f3OTO7D3gMqAS+5u6HzexB4KC77wfuM7PbgVlgBPhIIYsWuZLBAiwOnU036JIoyuWkKO5+ADiQ9doDGY8/lee6RFZtYXHopsKdFNVi0RJFulJUYmdgPEFtVQXNdTn1V1ZFi0VLFCnQJXYGxqZpb8r/4tDZtFi0RI0CXWJnYDxR0BOigU1NdQszakSiQIEusTM4nlhYhKKQ2pvUQ5doUaBL7AyMF2Zx6GxaLFqiRoEusTI9O8/opdkiDblosWiJFgW6xMqrUxaL00PP3KdI2BToEivBlZvFGkMHBbpEhwJdYqWYPfTgl4Zu0CVRoUCXWBkM7uNShJOiWixaokaBLrEyMJ6gwmBjQ+EDXYtFS9Qo0CVWBsYSbGyspbKisFeJBrQUnUSJAl1iZWB8uihTFgMKdIkSBbrESrEu+w8o0CVKFOgSK8W67D+gxaIlShToEhvzSWdoojiX/QeCxaJHL80WbZ8iS1GgS2wMTyZIenHmoAd0cZFEiQJdYiO4lW1Rx9C1WLREiAJdYqMYS89l02LREiUKdImNhcWhNeQiZUqBLrFxbqx4l/0HtFi0RIkCXWKjf3SajQ011FZVFm2fWixaokSBLrFxfmyazc3FGz8PtDfWagxdIkGBLrHRPzpNZ0vxA31zc50CXSJBgS6xcX5sms0hBHpHSx39Fy/palEJnQJdYmF6dp4LkzN0hjDk0tlSx+TMPOOJuaLvWySTAl1iIbioKJweej0A50Z1YlTClVOgm9kdZnbMzHrM7P5Ftv+2mb1oZofM7PtmtiP/pYosrX/0EkAoY+jBPvsV6BKyZQPdzCqBh4A7gT3APWa2J6vZz4G97n4D8E3gC/kuVORKgjnoHSEMuQT7PJf+pSISllx66DcDPe5+wt1ngEeAuzMbuPsP3X0q/fRnQFd+yxS5smC4oyOkWS5m6qFL+HIJ9K3AmYznvenXlvIbwPcW22Bm95rZQTM7ODg4mHuVIss4NzZNQ00lTXXVRd93TVUFbY21GkOX0OX1pKiZ/TqwF/jiYtvd/WF33+vue9vb2/O5aylz50anQ+mdBzpb6tRDl9BV5dCmD9iW8bwr/dprmNntwGeBd7q7rrKQojo3Fm6gdzTXcXp4avmGIgWUSw/9KWC3mXWbWQ2wD9if2cDM3gT8CXCXuw/kv0yRKzs3Ok1Hc31o++9sqeOsTopKyJYNdHefA+4DHgOOAI+6+2Eze9DM7ko3+yLQCHzDzJ41s/1LfJxI3s0nnYHxBB0txbvLYraOlnrGp+eY0MVFEqJchlxw9wPAgazXHsh4fHue6xLJ2dBEgvmkL1zgE4ZgLvq50Wmu3tQYWh1S3nSlqJS8hSmLIcxBD3RkBLpIWBToUvL6LqbGrresD3eWC7x6xapIGBToUvL6RlIh2rV+XWg1bG5WD13Cp0CXktd38RKNtVU01+d0Sqgg6qor2dBQw1kFuoRIgS4lr3fkElvX12NmodaxdX39wvCPSBgU6FLy+i5eYmtreDNcAl2t9fSO6OIiCY8CXUpe38gUW9eHH+jbNqyjb0QrF0l4FOhS0sanZxmbnotMDz0xl2RwQne+kHAo0KWkBWPWUeihd6V/qfSOaBxdwqFAl5IWTFmMRg89NW1SgS5hUaBLSQt66F0R6KEH/0o4c0EnRiUcCnQpaX0jlxYWmAhbQ20VGxtq1EOX0CjQpaT1XkzNQa+oCHcOekBTFyVMCnQpacFFRVHR1bpuYVxfpNgU6FLSXhmeZMfG8O7hkq2rtZ7ei5dIJjUXXYpPgS4la3RqlpGp2cgF+sxckiHNRZcQKNClZJ2+MAnAjo0NIVfyqq4NqV8uZzSOLiFQoEvJChZl3hmhQN+eDnQtGC1hUKBLyTo9nOqhByEaBdta11FhcGpoMuxSpAwp0KVknRqeYnNzLfU1lWGXsqCmqoKu1nWcVA9dQqBAl5J1engyUuPnge62Bk4OTYRdhpQhBbqUrNPDU+yI0HBLoLutgVNDU7qNrhSdAl1K0tTMHAPjCXa2RbOHPpGY0210pegU6FKSglkkUTohGgh+yZwa0ji6FJcCXUrSyfQsku4I9tB3pWvSOLoUmwJdSlLPQCosd7VHL9C3rK+nprKCk+qhS5Ep0KUkHR+YoKu1nnU1VWGXcpnKCmPbhnr10KXocgp0M7vDzI6ZWY+Z3b/I9lvN7BkzmzOzX8l/mSKv1TMwwdWbGsMuY0ndbY2cGNTFRVJcywa6mVUCDwF3AnuAe8xsT1azV4CPAn+d7wJFss0nnZcHJ9gd4UC/tqORk0OTzMwlwy5FykguPfSbgR53P+HuM8AjwN2ZDdz9lLsfAvTtlYI7c2GKmbkkuzc1hV3Kkq7Z3MRc0hdO3ooUQy6BvhU4k/G8N/3aipnZvWZ20MwODg4OruYjRBZOiF4V6R566pfN0XNjIVci5aSoJ0Xd/WF33+vue9vb24u5a4mR4+lAj/IY+q62RqoqjJfOj4ddipSRXAK9D9iW8bwr/ZpIKI4PjLOpqZaW+uqwS1lSTVUF3W0NHDunmS5SPLkE+lPAbjPrNrMaYB+wv7BliSztxbNjXN/ZHHYZy7q2o0k9dCmqZQPd3eeA+4DHgCPAo+5+2MweNLO7AMzsF8ysF/gw8CdmdriQRUv5SszN0zMwwZ4tJRDom5t45cIUUzNzYZciZSKnqzLc/QBwIOu1BzIeP0VqKEakoI6fn2Au6byuFAJ94cToODdtbw25GikHulJUSsrhs6MAvG5LS8iVLO8NXakan+8dDbkSKRcKdCkph8+O0VhbFcn7oGfraK6jrbGWQwp0KRIFupSU1AnRJioqLOxSlmVm3NjVwqHei2GXImVCgS4lY3Y+yQtnR3n91ugPtwRu6FpPz+AEkwmdGJXCU6BLyTjaP870bLKkTjDe0NWCO7zQp2EXKTwFupSMp09fAODNO0on0IMToxpHl2JQoEvJePqVi3S21LFlfX3YpeSsrbGWbRvqefr0SNilSBlQoEvJeOb0SEkNtwTe0r2RJ08Ok0x62KVIzCnQpSScvXiJvouXuKmEhlsCb+newMjU7MJNxUQKRYEuJeEnPUMAvO2qjSFXsnK37ErV/OTJ4ZArkbhToEtJ+GnPEG2NtVzXEd1FLZbS1VrPlpY6njxxIexSJOYU6BJ5yaTz054h3nH1Rsyif0FRNjPjbVe38ZOeIebmtaiXFI4CXSLv6LlxhiZmePvVbWGXsmq3XbeJ0Uuzmu0iBaVAl8h74sh5zOCd15TuKlfv2N1GdaXxg6MDYZciMaZAl8g78Hw/b97eyqbmurBLWbWmumre0r2RJ46cD7sUiTEFukTaqaFJjp4b5843dIZdypq9Z89mXh6c1MLRUjAKdIm07z7fD8Adr+8IuZK1+8ANnVRVGN9+RkvySmEo0CWykknn0YNnuLl7A1tL6HL/pWxsrOVd17bznWf7mNdVo1IACnSJrH8+Mczp4Sn+zc3bwy4lbz54UxfnxxL8UCdHpQAU6BJZf/7/TrF+XXUshlsC79mzmS0tdfzpP50IuxSJIQW6RNLRc2M8/uJ5PvLWndRVV4ZdTt5UV1bwsbd38+TJC1rJSPJOgS6R9IePH6ehppKPvX1n2KXk3b6bt7F+XTWf/4ejuGssXfJHgS6R89OeIf7h8Dn+wzuvYv26mrDLybumumo+ddtuftozzPePaCxd8keBLpEyPj3Lf/3282zbUM+9t+4Ku5yC+fVbdnD1pkZ+7zsvMDI5E3Y5EhMKdImMZNK5/1vPc+bCFF/+1TfGauw8W3VlBX/4a29keDLB73zjOd20S/JCgS6RkEw6/+1vX+C7z/dz/53X8Qs7N4RdUsG9fmsLD/zi6/jB0QE+/a3nFeqyZlVhFyAyPJHg0986xBNHBvjEO6/i3luvCrukovm3t+xgZHKGLz/+EgPj03zpwzeW9D1rJFw59dDN7A4zO2ZmPWZ2/yLba83s6+ntT5rZzrxXKrFzYXKGP/5RD+/+0o/50bFB/vtdr+PTd1wbdllF98nbdvOFD93Akycu8O4v/Zg/+v5xBscTYZclJciWmzZlZpXAS8B7gF7gKeAed38xo81vAje4+yfMbB/wy+7+a1f63L179/rBgwfXWr9EnLtzaXae0UuzDE/McHJokuMDE/zsxDDPnB5hLuncek07D3zgeq7eVHqrEeXTyaFJ/sd3X+SJIwNUVhg3bV/PLbs2sntzE90bG9jYWMOGhppYn1uQ5ZnZ0+6+d9FtOQT6W4HPufv70s8/A+Duf5DR5rF0m382syrgHNDuV/jw1Qb6o0+d4eGMq+yyd3HZDv2KT5d9f/bfwLNaXLZ9mWnFed/fMu/PbrH8+1dY3zLtE7NJZrLGhs3g+o5mbr2mnQ/etJVrNpd3kGd7eXCCv3mmlx+/NMiLZ8fIvu1LTWUFNVUVVFda+r8VVFakVnIK1nMKVnZaWN/JWHT7a9pI0Xzytt384o1bVvXeKwV6LmPoW4EzGc97gbcs1cbd58xsFNgIDGUVci9wL8D27au7P0drQw3XZgeAXfHpZcuWXb59be+/fP9Z7Zf9/BW+f5kC8r6/y95/5QjI3FxbVUlLfTXr11XTuq6aHRsb6G5rUC/zCq5qb+R333cdv/u+65ienefk0CSnh6cYmZrhwuQMY9OzzM45s/NJZueTzMwlSfqrv/qD37GvPvfXPM/8rZvdYZDiaKmvLsjnFvWkqLs/DDwMqR76aj7jPXs28549m/Nal0hU1VVXcn1nM9d3NoddipSAXE6K9gHbMp53pV9btE16yKUFGM5HgSIikptcAv0pYLeZdZtZDbAP2J/VZj/wkfTjXwF+cKXxcxERyb9lh1zSY+L3AY8BlcDX3P2wmT0IHHT3/cCfAX9pZj3ABVKhLyIiRZTTGLq7HwAOZL32QMbjaeDD+S1NRERWQpf+i4jEhAJdRCQmFOgiIjGhQBcRiYllL/0v2I7NBoHTq3x7G1lXoUaE6lqZqNYF0a1Nda1MHOva4e7ti20ILdDXwswOLnUvgzCprpWJal0Q3dpU18qUW10achERiQkFuohITJRqoD8cdgFLUF0rE9W6ILq1qa6VKau6SnIMXURELleqPXQREcmiQBcRiYnIBrqZfdjMDptZ0sz2Zm37THpB6mNm9r4l3t+dXrC6J72AdU0Bavy6mT2b/nPKzJ5dot0pM3s+3a7gC6ma2efMrC+jtvcv0e6Ki38XoK4vmtlRMztkZt82s/VLtCvK8Yri4udmts3MfmhmL6a//59apM27zGw04+f7wGKfVaD6rvizsZQ/Sh+zQ2Z2UxFqujbjWDxrZmNm9ltZbYpyzMzsa2Y2YGYvZLy2wcweN7Pj6f+2LvHej6TbHDezjyzWZlnuHsk/wPXAtcCPgL0Zr+8BngNqgW7gZaBykfc/CuxLP/4K8B8LXO+XgAeW2HYKaCvisfsc8J+XaVOZPna7gJr0Md1T4LreC1SlH38e+HxYxyuXvz/wm8BX0o/3AV8vws+uE7gp/biJ1ALt2XW9C/j7Yn2fVvKzAd4PfI/UyoW3AE8Wub5KUmsa7wjjmAG3AjcBL2S89gXg/vTj+xf73gMbgBPp/7amH7eudP+R7aG7+xF3P7bIpruBR9w94e4ngR7g5swGllr08t3AN9Mv/QXwS4WqNb2/XwX+T6H2UQA3Az3ufsLdZ4BHSB3bgnH3f3T3ufTTn5Fa/Sosufz97yb13YHUd+k2W25B1TVy9353fyb9eBw4QmrN3lJxN/C/PeVnwHoz6yzi/m8DXnb31V6Fvibu/n9JrQmRKfN7tFQWvQ943N0vuPsI8Dhwx0r3H9lAv4LFFq3O/sJvBC5mhMdibfLpXwHn3f34Etsd+Eczezq9UHYx3Jf+J+/XlvgnXi7HsZA+Tqont5hiHK9c/v6vWfwcCBY/L4r0EM+bgCcX2fxWM3vOzL5nZq8rVk0s/7MJ+3u1j6U7VmEds83u3p9+fA5YbFHkvBy3oi4Snc3MngA6Ftn0WXf/22LXs5gca7yHK/fO3+HufWa2CXjczI6mf5MXpC7gfwG/T+p/vt8nNRz08bXsLx91BcfLzD4LzAF/tcTH5P14lRozawS+BfyWu49lbX6G1JDCRPr8yHeA3UUqLbI/m/R5sruAzyyyOcxjtsDd3cwKNlc81EB399tX8bZcFq0eJvVPvap0z2qxNnmp0VKLYn8QePMVPqMv/d8BM/s2qX/ur+l/glyPnZn9KfD3i2zK5TjmvS4z+yjwAeA2Tw8eLvIZeT9ei1jJ4ue9VsTFz82smlSY/5W7/0329syAd/cDZvbHZtbm7gW/CVUOP5uCfK9ydCfwjLufz94Q5jEDzptZp7v3p4efBhZp00dqnD/QRer84YqU4pDLfmBfegZCN6nfsv+S2SAdFD8ktWA1pBawLlSP/3bgqLv3LrbRzBrMrCl4TOrE4AuLtc2XrDHLX15if7ks/p3vuu4A/gtwl7tPLdGmWMcrkoufp8fo/ww44u5fXqJNRzCWb2Y3k/r/uBi/aHL52ewH/l16tsstwGjGcEOhLfkv5bCOWVrm92ipLHoMeK+ZtaaHSN+bfm1lCn3Wd7V/SAVRL5AAzgOPZWz7LKkZCseAOzNePwBsST/eRSroe4BvALUFqvPPgU9kvbYFOJBRx3PpP4dJDT0U+tj9JfA8cCj9ZerMriv9/P2kZlG8XKS6ekiNEz6b/vOV7LqKebwW+/sDD5L6hQNQl/7u9KS/S7uKcIzeQWqo7FDGcXo/8Ingewbclz42z5E6ufy2Qtd1pZ9NVm0GPJQ+ps+TMUOtwLU1kArolozXin7MSP1C6Qdm0/n1G6TOu3wfOA48AWxIt90LfDXjvR9Pf9d6gI+tZv+69F9EJCZKcchFREQWoUAXEYkJBbqISEwo0EVEYkKBLiISEwp0EZGYUKCLiMTE/wfwP5WY92eP3wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "normal_dist = lambda x, mean, var: np.exp(- np.square(x - mean) / (2 * var)) / np.sqrt(2 * np.pi * var)\n",
    "\n",
    "def plot_normal_dist(mean, var, rmin=-10, rmax=10):\n",
    "    x = np.arange(rmin, rmax, 0.01)\n",
    "    y = normal_dist(x, mean, var)\n",
    "    fig = plt.plot(x, y)\n",
    "    \n",
    "# plain distribution\n",
    "data = model.lr(x_test)\n",
    "mean, var = map(float, [data.mean(), data.std() ** 2])\n",
    "plot_normal_dist(mean, var)\n",
    "print(\"Distribution on plain data:\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ccca30-4b2d-4baf-bada-0df4af35882c",
   "metadata": {},
   "source": [
    "Most of the data falls into [-5, 5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "917d6801-ff3d-466c-9ae2-cb5b9613d17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 0.8504331707954407\n",
      "Loss at epoch 2: 0.6863384246826172\n",
      "Loss at epoch 3: 0.6358115673065186\n",
      "Loss at epoch 4: 0.6193529367446899\n",
      "Loss at epoch 5: 0.6124349236488342\n",
      "Loss at epoch 6: 0.6089244484901428\n",
      "Loss at epoch 7: 0.6069258451461792\n",
      "Loss at epoch 8: 0.6057038307189941\n",
      "Loss at epoch 9: 0.6049202084541321\n",
      "Loss at epoch 10: 0.604399561882019\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "def train(model, optim, criterion, x, y, epochs=EPOCHS):\n",
    "    for e in range(1, epochs + 1):\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(f\"Loss at epoch {e}: {loss.data}\")\n",
    "    return model\n",
    "\n",
    "t_start = time()\n",
    "model = train(model, optim, criterion, x_train, y_train)\n",
    "t_end = time()\n",
    "print(f\"Plain model training took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9e0f622-2dac-431a-ad07-7dbe02eaf081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on plain test_set: 0.697604775428772\n"
     ]
    }
   ],
   "source": [
    "def accuracy(model, x, y):\n",
    "    out = model(x)\n",
    "    correct = torch.abs(y - out) < 0.5\n",
    "    return correct.float().mean()\n",
    "\n",
    "plain_accuracy = accuracy(model, x_test, y_test)\n",
    "print(f\"Accuracy on plain test_set: {plain_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d82c195-6ed4-4e77-991a-a948008a37f5",
   "metadata": {},
   "source": [
    "We will be comparing accuracies over encrypted data against the plain_accuracy we got here.\n",
    "\n",
    "## Training an Encrypted Logistic Regression Model on Encrypted Data\n",
    "\n",
    "## TenSEAL Context\n",
    "The TenSEALContext is a special object that holds different encryption keys and parameters for you, so that you only need to use a single object to make your encrypted computation instead of managing all the keys and the HE details. Basically, you will want to create a single TenSEALContext before doing your encrypted computation. Let's see how to create one !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d637bd-911b-4faf-b6d6-6ff7b2c23b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "# create TenSEALContext\n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_training.global_scale = 2 ** 21\n",
    "ctx_training.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808711fc-5579-4740-9605-7823bd18cf8a",
   "metadata": {},
   "source": [
    "### Model Encryption\n",
    "From the input data to the parameter update, a ciphertext will need a multiplicative depth of 6, 1 for the dot product operation, 2 for the sigmoid approximation, and 3 for the backprobagation phase. With a scale of around 20 bits, we need 6 coefficients modulus with the same bit-size as the scale, plus the last coeffcient, which needs more bits, we are already out of the 4096 polynomial modulus degree (which requires < 109 total bit count of the coefficients modulus, if we consider 128-bit security), so we will use 8192. This will allow us to batch up to 4096 values in a single ciphertext, but we are far away from this limitation, so we shouldn't even think about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd4cdf61-cbdb-4c75-a987-758b09556658",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedLR:\n",
    "    \n",
    "    def __init__(self, torch_lr):\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "        # we accumulate gradients and counts the number of iterations\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
    "        return enc_out\n",
    "    \n",
    "    def backward(self, enc_x, enc_out, enc_y):\n",
    "        out_minus_y = (enc_out - enc_y)\n",
    "        self._delta_w += enc_x * out_minus_y\n",
    "        self._delta_b += out_minus_y\n",
    "        self._count += 1\n",
    "        \n",
    "    def update_parameters(self):\n",
    "        if self._count == 0:\n",
    "            raise RuntimeError(\"You should at least run one forward iteration\")\n",
    "        # update weights\n",
    "        # We use a small regularization term to keep the output\n",
    "        # of the linear layer in the range of the sigmoid approximation\n",
    "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
    "        self.bias -= self._delta_b * (1 / self._count)\n",
    "        # reset gradient accumulators and iterations count\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(enc_x):\n",
    "        # We use the polynomial approximation of degree 3\n",
    "        # sigmoid(x) = 0.5 + 0.197 * x - 0.004 * x^3\n",
    "        # from https://eprint.iacr.org/2018/462.pdf\n",
    "        # which fits the function pretty well in the range [-5,5]\n",
    "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
    "    \n",
    "    def plain_accuracy(self, x_test, y_test):\n",
    "        # evaluate accuracy of the model on\n",
    "        # the plain (x_test, y_test) dataset\n",
    "        w = torch.tensor(self.weight)\n",
    "        b = torch.tensor(self.bias)\n",
    "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
    "        correct = torch.abs(y_test - out) < 0.5\n",
    "        return correct.float().mean()    \n",
    "    \n",
    "    def encrypt(self, context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fad76d4-cf5a-4317-b3a9-30fa71492ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeln = LR(n_features)\n",
    "eelr = EncryptedLR(modeln)\n",
    "eelr.encrypt(ctx_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f577c665-9888-4365-bcac-9ef285efb9d0",
   "metadata": {},
   "source": [
    "### Data Encryption using the same key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed389411-8ca9-440d-8f82-018b2e3bf920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the training_set took 11 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
    "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
    "t_end = time()\n",
    "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8c8a75-093f-4470-93d9-0b3ff10c4416",
   "metadata": {},
   "source": [
    "We compare the distribution of `x.dot(weight) + bias` in both plain and encrypted domains. Since our sigmoid approximation is only good in the range [-5,5] , we want to have all its inputs in that range. In order to do this, we need to keep our logistic regression parameters as small as possible, so we apply regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e30bba5-992e-40cd-a768-9f6815dad8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution on encrypted data:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encrypted distribution\n",
    "def encrypted_out_distribution(eelr, enc_x_test):\n",
    "    w = eelr.weight\n",
    "    b = eelr.bias\n",
    "    data = []\n",
    "    for enc_x in enc_x_test:\n",
    "        enc_out = enc_x.dot(w) + b\n",
    "        data.append(enc_out.decrypt())\n",
    "    data = torch.tensor(data)\n",
    "    mean, var = map(float, [data.mean(), data.std() ** 2])\n",
    "    plot_normal_dist(mean, var)\n",
    "    print(\"Distribution on encrypted data:\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "encrypted_out_distribution(eelr, enc_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35046dea-61a5-4266-9788-cc87b9bc0350",
   "metadata": {},
   "source": [
    "Most of the data falls into [-5,5], the sigmoid approximation should be good enough!\n",
    "\n",
    "We finally reached the last part, which is about training an encrypted logistic regression model on encrypted data! You can see that we decrypt the weights and re-encrypt them again after every epoch, this is necessary since after updating the weights at the end of the epoch, we can no longer use them to perform enough multiplications, so we need to get them back to the initial ciphertext level. In a real scenario, this would translate to sending the weights back to the secret-key holder for decryption and re-encryption. In that case, it will result in just a few Kilobytes of communication per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17c33f1f-f23e-4a21-9c52-2336e32aadc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at epoch #0 is 0.523952066898346\n",
      "Accuracy at epoch #1 is 0.6646706461906433\n",
      "Accuracy at epoch #2 is 0.628742516040802\n",
      "Accuracy at epoch #3 is 0.6556886434555054\n",
      "Accuracy at epoch #4 is 0.6317365169525146\n",
      "Accuracy at epoch #5 is 0.6467065811157227\n",
      "Accuracy at epoch #6 is 0.6317365169525146\n",
      "Accuracy at epoch #7 is 0.6347305178642273\n",
      "Accuracy at epoch #8 is 0.6317365169525146\n",
      "Accuracy at epoch #9 is 0.6317365169525146\n",
      "Accuracy at epoch #10 is 0.6347305178642273\n",
      "Encryption model training took 58 seconds\n",
      "\n",
      "Average time per epoch: 57 seconds\n",
      "Final accuracy is 0.6347305178642273\n",
      "Difference between plain and encrypted accuracies: 0.06287425756454468\n"
     ]
    }
   ],
   "source": [
    "eelr = EncryptedLR(LR(n_features))\n",
    "accuracy = eelr.plain_accuracy(x_test, y_test)\n",
    "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
    "t_startn = time()\n",
    "\n",
    "times = []\n",
    "for epoch in range(EPOCHS):\n",
    "    eelr.encrypt(ctx_training)\n",
    "    \n",
    "    # if you want to keep an eye on the distribution to make sure\n",
    "    # the function approxiamation is still working fine\n",
    "    # WARNING: this operation is time consuming\n",
    "    # encrypted_out_distribution(eelr, enc_x_train)\n",
    "    \n",
    "    t_start = time()\n",
    "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
    "        enc_out = eelr.forward(enc_x)\n",
    "        eelr.backward(enc_x, enc_out, enc_y)\n",
    "    eelr.update_parameters()\n",
    "    t_end = time()\n",
    "    times.append(t_end - t_start)\n",
    "    \n",
    "    eelr.decrypt()\n",
    "    accuracy = eelr.plain_accuracy(x_test, y_test)\n",
    "    print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
    "\n",
    "t_endn = time()\n",
    "print(f\"Encryption model training took {int(t_endn - t_startn)} seconds\")\n",
    "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
    "print(f\"Final accuracy is {accuracy}\")\n",
    "\n",
    "diff_accuracy = plain_accuracy - accuracy\n",
    "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
    "if diff_accuracy < 0:\n",
    "    print(\"Oh! We got a better accuracy when training on encrypted data! The noise was on our side...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e2d6a-4c22-466a-b983-0e3bb7a18b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('climate')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d7967a8d9afcf4b31f4d35ec92712493ac98bed77dd4624f3d610c11e265b0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
